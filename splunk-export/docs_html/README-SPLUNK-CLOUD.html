<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DMA Splunk Cloud Export - README | Dynatrace Migration Assistant</title>
    <style>
        :root {
            --db-header-bg: #14172b;
            --db-nav-dark: #1a1d2e;
            --db-accent-purple: #7c5dc7;
            --db-accent-blue: #4da6e8;
            --db-accent-green: #6abf4b;
            --content-bg: #ffffff;
            --content-card: #f8f9fa;
            --text-dark: #1a1a2e;
            --text-body: #3a3a4a;
            --text-muted: #6c757d;
            --text-light: #ffffff;
            --accent-blue: #1456ff;
            --success: #6abf4b;
            --border-light: #e0e0e0;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
            line-height: 1.45;
            color: var(--text-dark);
            background: var(--content-bg);
            font-size: 14px;
        }

        /* Header - Compact */
        .header-banner {
            background: var(--db-header-bg);
            padding: 20px 16px;
            text-align: center;
        }
        .header-content { max-width: 900px; margin: 0 auto; }
        .logo-container {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
            margin-bottom: 8px;
        }
        .logo-image { height: 36px; width: 36px; object-fit: contain; }
        .logo-text { font-size: 1.5em; font-weight: 700; color: var(--text-light); }
        .logo-text .highlight { color: var(--db-accent-purple); }
        .header-tagline {
            color: rgba(255,255,255,0.6);
            font-size: 0.85em;
            margin-bottom: 10px;
        }
        .version-badge {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            background: rgba(255,255,255,0.08);
            border: 1px solid rgba(255,255,255,0.15);
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.75em;
            color: rgba(255,255,255,0.7);
        }
        .version-badge .dot { width: 5px; height: 5px; background: var(--success); border-radius: 50%; }
        .doc-title { margin-top: 12px; padding-top: 10px; border-top: 1px solid rgba(255,255,255,0.1); }
        .doc-title h2 { color: var(--text-light); font-size: 1.1em; font-weight: 600; margin: 0; padding: 0; border: none; }

        /* Navigation - Compact */
        .doc-nav {
            background: var(--db-nav-dark);
            position: sticky;
            top: 0;
            z-index: 100;
            border-bottom: 1px solid rgba(255,255,255,0.05);
        }
        .doc-nav-inner { max-width: 1100px; margin: 0 auto; display: flex; flex-wrap: wrap; justify-content: center; }
        .doc-nav a {
            color: rgba(255,255,255,0.55);
            text-decoration: none;
            font-size: 0.78em;
            font-weight: 500;
            padding: 10px 14px;
            border-bottom: 2px solid transparent;
            transition: all 0.15s;
        }
        .doc-nav a:hover { color: var(--text-light); background: rgba(255,255,255,0.05); border-bottom-color: var(--db-accent-purple); }

        /* Content - Tight */
        .content { max-width: 900px; margin: 0 auto; padding: 20px 24px 30px; }

        /* Typography - Compact */
        h1 {
            color: var(--text-dark);
            font-size: 1.6em;
            font-weight: 700;
            margin-bottom: 4px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--db-accent-purple);
        }
        h2 {
            color: var(--text-dark);
            font-size: 1.25em;
            font-weight: 600;
            margin-top: 20px;
            margin-bottom: 6px;
            padding-bottom: 4px;
            border-bottom: 1px solid var(--border-light);
        }
        h3 {
            color: var(--text-dark);
            font-size: 1.05em;
            font-weight: 600;
            margin-top: 14px;
            margin-bottom: 4px;
        }
        h4 {
            color: var(--text-dark);
            font-size: 0.95em;
            font-weight: 600;
            margin-top: 10px;
            margin-bottom: 3px;
        }
        h5, h6 {
            color: var(--text-dark);
            font-size: 0.9em;
            font-weight: 600;
            margin-top: 8px;
            margin-bottom: 2px;
        }
        p { margin-bottom: 8px; color: var(--text-body); }
        strong { color: var(--text-dark); font-weight: 600; }
        a { color: var(--accent-blue); text-decoration: none; }
        a:hover { text-decoration: underline; }

        /* Code - Compact */
        pre {
            background: #1e1e2e;
            border: 1px solid #2d2d3d;
            border-radius: 4px;
            padding: 10px 12px;
            overflow-x: auto;
            margin: 8px 0;
            font-family: 'SF Mono', Monaco, Consolas, monospace;
            font-size: 0.82em;
            line-height: 1.4;
            color: #e0e0e0;
        }
        code {
            background: #f0f0f2;
            color: #c7254e;
            padding: 1px 4px;
            border-radius: 3px;
            font-family: 'SF Mono', Monaco, Consolas, monospace;
            font-size: 0.85em;
        }
        pre code { background: none; padding: 0; color: #e0e0e0; }

        /* Tables - Compact */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 10px 0;
            font-size: 0.88em;
            border: 1px solid var(--border-light);
        }
        th {
            background: var(--db-nav-dark);
            color: var(--text-light);
            padding: 8px 10px;
            text-align: left;
            font-weight: 600;
            font-size: 0.8em;
            text-transform: uppercase;
            letter-spacing: 0.02em;
        }
        td {
            padding: 7px 10px;
            border-bottom: 1px solid var(--border-light);
            color: var(--text-body);
        }
        tr:last-child td { border-bottom: none; }
        tr:nth-child(even) td { background: #f9f9fb; }

        /* Lists - Tight */
        ul, ol { margin: 6px 0; padding-left: 20px; color: var(--text-body); }
        li { margin-bottom: 2px; }
        li::marker { color: var(--db-accent-purple); }

        /* Blockquotes */
        blockquote {
            background: var(--content-card);
            border-left: 3px solid var(--db-accent-purple);
            border-radius: 0 4px 4px 0;
            padding: 8px 12px;
            margin: 10px 0;
        }
        blockquote p { margin-bottom: 0; }

        /* HR - Minimal */
        hr { border: none; border-top: 1px solid var(--border-light); margin: 16px 0; }

        /* Footer - Compact */
        .footer { background: var(--db-nav-dark); padding: 20px 16px; text-align: center; }
        .footer-content { max-width: 600px; margin: 0 auto; }
        .footer-logo { font-size: 1em; font-weight: 700; color: var(--text-light); margin-bottom: 6px; }
        .footer-logo .highlight { color: var(--db-accent-purple); }
        .footer p { color: rgba(255,255,255,0.5); font-size: 0.8em; margin-bottom: 4px; }
        .footer-links { display: flex; justify-content: center; gap: 16px; margin-top: 10px; flex-wrap: wrap; }
        .footer-links a { color: rgba(255,255,255,0.45); font-size: 0.75em; }
        .footer-links a:hover { color: var(--db-accent-purple); text-decoration: none; }
        .footer-copyright {
            margin-top: 12px;
            padding-top: 10px;
            border-top: 1px solid rgba(255,255,255,0.08);
            font-size: 0.7em;
            color: rgba(255,255,255,0.35);
        }

        /* Print */
        @media print {
            .doc-nav, .footer { display: none; }
            .content { max-width: 100%; padding: 12px; }
            .header-banner { padding: 12px; }
        }

        /* Responsive */
        @media (max-width: 768px) {
            .header-banner { padding: 16px 12px; }
            .logo-text { font-size: 1.2em; }
            .logo-image { height: 28px; width: 28px; }
            .content { padding: 16px 12px; }
            h1 { font-size: 1.4em; }
            h2 { font-size: 1.15em; }
            table { font-size: 0.82em; }
            th, td { padding: 6px 8px; }
            .doc-nav a { padding: 8px 10px; font-size: 0.72em; }
        }
    </style>
</head>
<body>
    <header class="header-banner">
        <div class="header-content">
            <div class="logo-container">
                <img class="logo-image" src="dma-symbol.png" alt="DMA" onerror="this.style.display='none'" />
                <div class="logo-text">Dynatrace Migration Assistant</div>
            </div>
            <p class="header-tagline">Migration Intelligence Platform for Splunk to Dynatrace</p>
            <span class="version-badge"><span class="dot"></span>Version 4.0.1</span>
            <div class="doc-title"><h2>DMA Splunk Cloud Export - README</h2></div>
        </div>
    </header>

    <nav class="doc-nav">
        <div class="doc-nav-inner">
            <a href="README-SPLUNK-ENTERPRISE.html">Enterprise README</a>
            <a href="README-SPLUNK-CLOUD.html">Cloud README</a>
            <a href="SPLUNK-ENTERPRISE-EXPORT-SPECIFICATION.html">Enterprise Spec</a>
            <a href="SPLUNK-CLOUD-EXPORT-SPECIFICATION.html">Cloud Spec</a>
            <a href="SCRIPT-GENERATED-ANALYTICS-REFERENCE.html">Analytics Reference</a>
            <a href="EXPORT-SCHEMA.html">Export Schema</a>
        </div>
    </nav>

    <main class="content">
<h1>DMA Splunk Cloud Export Script</h1>
<h2>Prerequisites Guide for Splunk Cloud (Classic & Victoria Experience)</h2>
<p>
<strong>Version</strong>: 4.3.0
<strong>Last Updated</strong>: February 2026
<strong>Related Documents</strong>: <a href="SCRIPT-GENERATED-ANALYTICS-REFERENCE.md">Script-Generated Analytics Reference</a> | <a href="SPLUNK-CLOUD-EXPORT-SPECIFICATION.md">Cloud Export Specification</a>
</p>
<h3>What's New in v4.3.0</h3>
<h4>Resume Collection (<code>--resume-collect</code>)</h4>
<p>
Pass a previous <code>.tar.gz</code> export to the script, and it will extract it, detect what has already been collected, fill in the gaps, and create a versioned output archive (<code>-v1</code>, <code>-v2</code>, etc.). This is ideal for exports that timed out or were interrupted before completion. You can also add <code>--rbac</code> or <code>--usage</code> flags to complete exports that were originally run without those options.
</p>
<h4>12-Hour Max Runtime</h4>
<p>
<code>MAX<em>TOTAL</em>TIME</code> has been increased to <code>43200</code> seconds (12 hours), up from 14400 (4 hours), to support very large Splunk Cloud environments with thousands of apps and dashboards.
</p>
<h4>PowerShell Edition</h4>
<p>
A new <code>dma-splunk-cloud-export.ps1</code> script provides identical functionality for Windows environments. It requires only PowerShell 5.1+ and has zero external dependencies (no Python, curl, or jq needed). See the <a href="#powershell-edition">PowerShell Edition</a> section below for details.
</p>
<h4>Proxy Support (<code>--proxy</code> / <code>-Proxy</code>)</h4>
<p>
Both Cloud scripts now support routing all connections through a corporate proxy server. This is essential for enterprise environments where direct internet access to Splunk Cloud is blocked by a firewall or security policy.
</p>
<pre><code class="language-bash"># Bash: Route through corporate proxy
./dma-splunk-cloud-export.sh --proxy http://proxy.company.com:8080

# PowerShell: Route through corporate proxy
.\dma-splunk-cloud-export.ps1 -Proxy &quot;http://proxy.company.com:8080&quot;</code></pre>
<p>
When a proxy is configured:
</p>
<ul>
<li>DNS resolution and TCP port connectivity tests are skipped (the proxy handles routing)</li>
<li>All <code>curl</code> / <code>Invoke-WebRequest</code> calls are routed through the proxy</li>
<li>If not provided via flag, the script prompts interactively during setup (default: No)</li>
<li>If connectivity fails, error messages include proxy-specific troubleshooting guidance</li>
</ul>
<h3>Previous v4.2.4 Changes</h3>
<h4>Two-Archive Anonymization (Preserves Original Data)</h4>
<p>
When anonymization is enabled, the script now creates <strong>TWO archives</strong>:
</p>
<ul>
<li><code>{export_name}.tar.gz</code> - <strong>Original, untouched data</strong> (keep for your records)</li>
<li><code>{export<em>name}</em>masked.tar.gz</code> - <strong>Anonymized copy</strong> (safe to share)</li>
</ul>
<p>
This preserves the original data in case anonymization corrupts files. Users can re-run anonymization on the original without re-running the entire export.
</p>
<h4>Performance Optimizations</h4>
<ul>
<li><strong>RBAC/Users collection now OFF by default</strong> - Use <code>--rbac</code> flag to enable</li>
<li><strong>Usage analytics now OFF by default</strong> - Use <code>--usage</code> flag to enable</li>
<li><strong>Faster defaults</strong>: Batch size 250 (was 100), API delay 50ms (was 250ms)</li>
<li><strong>Optimized queries</strong>: Sampling for expensive regex extractions, <code>max()</code> instead of <code>latest()</code> for faster aggregations</li>
</ul>
<h3>Previous v4.2.0 Changes</h3>
<ul>
<li><strong>App-Centric Dashboard Structure (v2)</strong>: Dashboards now saved to <code>{AppName}/dashboards/classic/</code> and <code>{AppName}/dashboards/studio/</code> to prevent name collisions</li>
<li><strong>Manifest Schema v4.0</strong>: Added <code>archive<em>structure</em>version: "v2"</code> for DMA to detect the new structure</li>
<li><strong>No More Flat Folders</strong>: Removed <code>dashboards<em>classic/</code> and <code>dashboards</em>studio/</code> at root level</li>
</ul>
<hr>
<blockquote><p><strong>Developed for Dynatrace One by Enterprise Solutions & Architecture</strong></p></blockquote>
<blockquote><p><em>An ACE Services Division of Dynatrace</em></p></blockquote>
<hr>
<h2>Quick Start</h2>
<pre><code class="language-bash"># This script runs from YOUR machine (not on Splunk Cloud)
# You need network access to your Splunk Cloud instance

./dma-splunk-cloud-export.sh</code></pre>
<h3>Quick Start (PowerShell - Windows)</h3>
<pre><code class="language-powershell"># This script runs from YOUR Windows machine (not on Splunk Cloud)
.\dma-splunk-cloud-export.ps1

# Non-interactive with token
.\dma-splunk-cloud-export.ps1 -Stack &quot;acme-corp.splunkcloud.com&quot; -Token &quot;your-token&quot;</code></pre>
<hr>
<h2>How This Differs from Enterprise Export</h2>
<table>
<thead>
<tr><th>Aspect</th><th>Enterprise Script</th><th>Cloud Script (Bash)</th><th>Cloud Script (PowerShell)</th></tr>
</thead>
<tbody>
<tr><td><strong>Where you run it</strong></td><td>ON the Splunk server</td><td>ANYWHERE (your laptop, jump host)</td><td>ANYWHERE (Windows machine)</td></tr>
<tr><td><strong>Access method</strong></td><td>SSH + File system</td><td>REST API only</td><td>REST API only</td></tr>
<tr><td><strong>What you need</strong></td><td>SSH access + splunk user</td><td>Network access + API credentials</td><td>Network access + API credentials</td></tr>
<tr><td><strong>File reading</strong></td><td>Reads props.conf, etc.</td><td>Reconstructs from REST API</td><td>Reconstructs from REST API</td></tr>
<tr><td><strong>Dependencies</strong></td><td>bash, tar</td><td>bash, curl, Python 3</td><td>PowerShell 5.1+ only (zero external deps)</td></tr>
</tbody>
</table>
<hr>
<h2>Prerequisites Checklist</h2>
<h3>1. Network Access</h3>
<pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                         NETWORK REQUIREMENTS                             │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  Your machine must be able to reach:                                     │
│                                                                          │
│    https://&lt;your-stack&gt;.splunkcloud.com:8089                            │
│                                                                          │
│  This is the Splunk Cloud REST API management port.                     │
│                                                                          │
│  TEST IT:                                                                │
│  $ curl -I https://acme-corp.splunkcloud.com:8089/services/server/info  │
│                                                                          │
│  If this fails, check:                                                   │
│  • Corporate firewall rules                                              │
│  • VPN requirements                                                      │
│  • Splunk Cloud IP allowlist settings                                   │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘</code></pre>
<h3>2. Splunk Cloud Credentials</h3>
<p>
You need ONE of the following:
</p>
<h4>Option A: API Token (Recommended)</h4>
<pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                      CREATING AN API TOKEN                               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  1. Log into Splunk Cloud web UI                                        │
│     https://your-stack.splunkcloud.com                                  │
│                                                                          │
│  2. Click Settings (gear icon) → Tokens                                 │
│                                                                          │
│  3. Click &quot;New Token&quot;                                                   │
│                                                                          │
│  4. Configure the token:                                                │
│     • Name: DMA Export Token                                     │
│     • Expiration: Set appropriate (e.g., 7 days)                        │
│     • Audience: Search (if asked)                                       │
│                                                                          │
│  5. Copy the token value (shown only once!)                             │
│                                                                          │
│  6. Store it securely - you&#039;ll need it for the export script            │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘</code></pre>
<h4>Option B: Username/Password</h4>
<ul>
<li>Your Splunk Cloud admin username and password</li>
<li>If MFA is required, you may need to create an API token instead</li>
</ul>
<h3>3. Required Permissions</h3>
<p>
The user or token must have these Splunk capabilities:
</p>
<table>
<thead>
<tr><th>Capability</th><th>Required?</th><th>What It's Used For</th></tr>
</thead>
<tbody>
<tr><td><code>admin_all_objects</code></td><td><strong>Required</strong></td><td>Access all apps and knowledge objects</td></tr>
<tr><td><code>list_users</code></td><td><strong>Required</strong></td><td>Collect user information</td></tr>
<tr><td><code>list_roles</code></td><td><strong>Required</strong></td><td>Collect role definitions</td></tr>
<tr><td><code>search</code></td><td><strong>Required</strong></td><td>Run usage analytics queries</td></tr>
<tr><td><code>rest_access</code></td><td><strong>Required</strong></td><td>Make REST API calls</td></tr>
<tr><td><code>list_indexes</code></td><td>Recommended</td><td>Get index metadata</td></tr>
</tbody>
</table>
<h4>Checking Your Permissions</h4>
<p>
Run this in Splunk Cloud search:
</p>
<pre><code class="language-spl">| rest /services/authentication/current-context
| table username, roles, capabilities</code></pre>
<h3>4. Local Machine Requirements</h3>
<table>
<thead>
<tr><th>Requirement</th><th>Purpose</th><th>Check Command</th></tr>
</thead>
<tbody>
<tr><td><code>bash</code> 4.0+</td><td>Script execution</td><td><code>bash --version</code></td></tr>
<tr><td><code>curl</code></td><td>REST API calls</td><td><code>curl --version</code></td></tr>
<tr><td><code>Python 3</code></td><td>JSON parsing</td><td><code>python3 --version</code></td></tr>
<tr><td>Disk space</td><td>Store export</td><td>500MB+ free</td></tr>
</tbody>
</table>
<h4>PowerShell Edition Requirements</h4>
<table>
<thead>
<tr><th>Requirement</th><th>Purpose</th><th>Check Command</th></tr>
</thead>
<tbody>
<tr><td>PowerShell 5.1+ or 7+</td><td>Script execution</td><td><code>$PSVersionTable.PSVersion</code></td></tr>
<tr><td>Windows 10 1803+</td><td>Built-in tar.exe</td><td><code>tar --version</code></td></tr>
<tr><td>Network access</td><td>REST API calls</td><td>Port 8089 to Splunk Cloud</td></tr>
<tr><td>No external dependencies</td><td>Pure PowerShell</td><td>No Python, curl, or jq needed</td></tr>
</tbody>
</table>
<hr>
<h2>Splunk Cloud Stack URL</h2>
<h3>Finding Your Stack URL</h3>
<p>
Your Splunk Cloud stack URL is the address you use to access Splunk Cloud:
</p>
<pre><code>https://&lt;stack-name&gt;.splunkcloud.com</code></pre>
<p>
<strong>Examples</strong>:
</p>
<ul>
<li><code>https://acme-corp.splunkcloud.com</code></li>
<li><code>https://mycompany-prod.splunkcloud.com</code></li>
<li><code>https://enterprise1.splunkcloud.com</code></li>
</ul>
<h3>Testing Connectivity</h3>
<pre><code class="language-bash"># Test if you can reach the REST API
curl -I &quot;https://your-stack.splunkcloud.com:8089/services/server/info&quot;

# Expected: HTTP/2 401 (Unauthorized - but reachable)
# If you get connection refused or timeout, check network/firewall</code></pre>
<hr>
<h2>Supported Splunk Cloud Types</h2>
<table>
<thead>
<tr><th>Cloud Type</th><th>Supported</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>Splunk Cloud Classic</td><td>✅ Yes</td><td>Legacy multi-tenant</td></tr>
<tr><td>Splunk Cloud Victoria Experience</td><td>✅ Yes</td><td>Current default</td></tr>
<tr><td>Splunk Cloud on AWS</td><td>✅ Yes</td><td>Single-tenant</td></tr>
<tr><td>Splunk Cloud on GCP</td><td>✅ Yes</td><td>Single-tenant</td></tr>
<tr><td>Splunk Cloud on Azure</td><td>✅ Yes</td><td>Single-tenant</td></tr>
</tbody>
</table>
<hr>
<h2>What Data Can Be Collected</h2>
<h3>✅ Fully Available via REST API</h3>
<table>
<thead>
<tr><th>Data Type</th><th>REST Endpoint</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>Dashboards</td><td><code>/data/ui/views</code></td><td>Classic + Dashboard Studio</td></tr>
<tr><td>Saved Searches</td><td><code>/saved/searches</code></td><td>Includes alerts, reports</td></tr>
<tr><td>Users</td><td><code>/authentication/users</code></td><td>Full user list</td></tr>
<tr><td>Roles</td><td><code>/authorization/roles</code></td><td>With capabilities</td></tr>
<tr><td>Macros</td><td><code>/admin/macros</code></td><td>All search macros</td></tr>
<tr><td>Eventtypes</td><td><code>/saved/eventtypes</code></td><td>Event classifications</td></tr>
<tr><td>Tags</td><td><code>/configs/conf-tags</code></td><td>Tag assignments</td></tr>
<tr><td>Lookup Definitions</td><td><code>/data/lookup-table-files</code></td><td>File metadata</td></tr>
<tr><td>Lookup Contents</td><td>Download via REST</td><td>CSV data</td></tr>
<tr><td>Field Extractions</td><td><code>/data/transforms/extractions</code></td><td>Regex extractions</td></tr>
<tr><td>Apps List</td><td><code>/apps/local</code></td><td>Installed apps</td></tr>
<tr><td>Index Settings</td><td><code>/data/indexes</code></td><td>Index configuration</td></tr>
</tbody>
</table>
<h3>⚠️ Partially Available</h3>
<table>
<thead>
<tr><th>Data Type</th><th>Limitation</th><th>Workaround</th></tr>
</thead>
<tbody>
<tr><td>Props.conf</td><td>No file access</td><td>Reconstructed from <code>/configs/conf-props</code></td></tr>
<tr><td>Transforms.conf</td><td>No file access</td><td>Reconstructed from <code>/configs/conf-transforms</code></td></tr>
<tr><td>Usage Analytics</td><td>Requires search</td><td>Run searches on <code>_audit</code> index</td></tr>
<tr><td>Index Sizes</td><td>Limited stats</td><td>Best-effort from API</td></tr>
</tbody>
</table>
<h3>❌ Not Available</h3>
<table>
<thead>
<tr><th>Data Type</th><th>Why</th><th>Impact</th></tr>
</thead>
<tbody>
<tr><td>Raw config files</td><td>No file system</td><td>Use REST reconstruction</td></tr>
<tr><td>$SPLUNK_HOME access</td><td>Cloud infrastructure</td><td>N/A</td></tr>
<tr><td>Audit.log file</td><td>No file system</td><td>Use <code>_audit</code> index search</td></tr>
<tr><td>License file</td><td>Cloud-managed</td><td>N/A</td></tr>
<tr><td>Deployment apps</td><td>Cloud-managed</td><td>N/A</td></tr>
</tbody>
</table>
<hr>
<h2>IP Allowlisting (If Required)</h2>
<p>
Some Splunk Cloud instances require IP allowlisting for API access:
</p>
<h3>Check If Required</h3>
<p>
Contact your Splunk Cloud admin or check:
</p>
<ul>
<li>Splunk Cloud Admin Config (if you have access)</li>
<li>Cloud Stack settings</li>
</ul>
<h3>Adding Your IP</h3>
<ol>
<li>Log into Splunk Cloud Admin Config</li>
<li>Go to IP Allowlist settings</li>
<li>Add your machine's public IP:</li>
</ol>
<pre><code class="language-bash"># Find your public IP
   curl ifconfig.me</code></pre>
<ol>
<li>Allow port 8089 (REST API)</li>
</ol>
<hr>
<h2>Running the Script</h2>
<h3>Basic Usage</h3>
<pre><code class="language-bash"># Make executable
chmod +x dma-splunk-cloud-export.sh

# Run interactively
./dma-splunk-cloud-export.sh</code></pre>
<h3>With Pre-set Values</h3>
<pre><code class="language-bash"># Set stack URL via environment
export SPLUNK_CLOUD_STACK=&quot;acme-corp.splunkcloud.com&quot;

# Set token via environment (more secure than command line)
export SPLUNK_CLOUD_TOKEN=&quot;your-api-token&quot;

./dma-splunk-cloud-export.sh</code></pre>
<h3>Non-Interactive Mode (for automation)</h3>
<pre><code class="language-bash">./dma-splunk-cloud-export.sh \
  --stack &quot;acme-corp.splunkcloud.com&quot; \
  --token &quot;$SPLUNK_CLOUD_TOKEN&quot; \
  --all-apps \
  --output /path/to/output</code></pre>
<hr>
<h2>Command-Line Arguments (Updated in v4.1.0)</h2>
<table>
<thead>
<tr><th>Argument</th><th>Description</th><th>Example</th></tr>
</thead>
<tbody>
<tr><td><code>--stack</code></td><td>Splunk Cloud stack URL</td><td><code>--stack acme.splunkcloud.com</code></td></tr>
<tr><td><code>--token</code></td><td>API token for authentication</td><td><code>--token "xxxxx"</code></td></tr>
<tr><td><code>--user</code></td><td>Username (if not using token)</td><td><code>--user admin</code></td></tr>
<tr><td><code>--password</code></td><td>Password (if not using token)</td><td><code>--password "xxx"</code></td></tr>
<tr><td><code>--apps</code></td><td>Comma-separated list of apps <strong>(NEW v4.1.0)</strong></td><td><code>--apps "search,myapp"</code></td></tr>
<tr><td><code>--all-apps</code></td><td>Export all applications (default)</td><td><code>--all-apps</code></td></tr>
<tr><td><code>--quick</code></td><td>Quick mode - skip analytics <strong>(TESTING ONLY - see warning)</strong></td><td><code>--quick</code></td></tr>
<tr><td><code>--scoped</code></td><td>Scope collections to selected apps only <strong>(NEW v4.1.0)</strong></td><td><code>--scoped</code></td></tr>
<tr><td><code>--no-usage</code></td><td>Skip usage analytics collection</td><td><code>--no-usage</code></td></tr>
<tr><td><code>--skip-internal</code></td><td>Skip searches requiring _internal index</td><td><code>--skip-internal</code></td></tr>
<tr><td><code>--output</code></td><td>Output directory</td><td><code>--output /path/to/output</code></td></tr>
<tr><td><code>--rbac</code></td><td>Enable RBAC/user collection (OFF by default)</td><td><code>--rbac</code></td></tr>
<tr><td><code>--resume-collect FILE</code></td><td>Resume from previous .tar.gz archive <strong>(NEW v4.3.0)</strong></td><td><code>--resume-collect ./previous.tar.gz</code></td></tr>
<tr><td><code>--proxy URL</code></td><td>Route all connections through a proxy server <strong>(NEW v4.3.0)</strong></td><td><code>--proxy http://proxy:8080</code></td></tr>
<tr><td><code>-d, --debug</code></td><td>Enable verbose debug logging <strong>(NEW v4.1.0)</strong></td><td><code>--debug</code></td></tr>
<tr><td><code>--help</code></td><td>Show help message</td><td><code>--help</code></td></tr>
</tbody>
</table>
<blockquote><p><strong>Note</strong>: PowerShell equivalents use <code>-</code> prefix (e.g., <code>-Stack</code>, <code>-Token</code>, <code>-Rbac</code>, <code>-Usage</code>, <code>-ResumeCollect</code>, <code>-Proxy</code>)</p></blockquote>
<h3>App-Scoped Export Mode (NEW in v4.1.0)</h3>
<p>
For large Splunk Cloud environments, dramatically reduce export time by targeting specific apps:
</p>
<pre><code class="language-bash"># Export only specific apps (fastest option)
./dma-splunk-cloud-export.sh \
  --stack acme.splunkcloud.com \
  --token &quot;$TOKEN&quot; \
  --apps &quot;search,myapp,security_essentials&quot; \
  --quick

# Scoped mode - exports app configs + only users/searches related to those apps
./dma-splunk-cloud-export.sh \
  --stack acme.splunkcloud.com \
  --token &quot;$TOKEN&quot; \
  --apps &quot;myapp,otherapp&quot; \
  --scoped</code></pre>
<table>
<thead>
<tr><th>Mode</th><th>What It Does</th><th>Use When</th></tr>
</thead>
<tbody>
<tr><td><code>--quick</code></td><td>App configs only, no global analytics</td><td><strong>Testing/validation only</strong> - NOT for migration analysis</td></tr>
<tr><td><code>--scoped</code></td><td>App configs + app-filtered users/usage</td><td>You want usage data but only for selected apps</td></tr>
<tr><td>(default)</td><td>Full export of all apps + global analytics</td><td><strong>Recommended</strong> - Full migration analysis</td></tr>
</tbody>
</table>
<blockquote><p><strong>⚠️ CRITICAL WARNING: Do NOT use <code>--quick</code> for Migration Analysis</strong></p></blockquote>
<p>
>
</p>
<blockquote><p>The <code>--quick</code> flag is intended <strong>ONLY for testing and script validation</strong>, not for actual migration planning. Using <code>--quick</code> eliminates critical data needed for migration analysis:</p></blockquote>
<p>
>
</p>
<blockquote><p>- <strong>Usage Analytics</strong>: Who uses which dashboards/alerts, how often, and when last accessed</p></blockquote>
<blockquote><p>- <strong>User & RBAC Data</strong>: Migration audience identification, role mappings, permission structures</p></blockquote>
<blockquote><p>- <strong>Search Activity</strong>: Which saved searches are actively used vs. abandoned</p></blockquote>
<blockquote><p>- <strong>Priority Assessment</strong>: Data needed to determine migration priority and phasing</p></blockquote>
<p>
>
</p>
<blockquote><p><strong>Without this data, you cannot:</strong></p></blockquote>
<blockquote><p>- Identify which assets are actually being used vs. unused/abandoned</p></blockquote>
<blockquote><p>- Understand who your migration audiences are</p></blockquote>
<blockquote><p>- Prioritize which dashboards/alerts to migrate first</p></blockquote>
<blockquote><p>- Make informed decisions about what may or may not be needed</p></blockquote>
<p>
>
</p>
<blockquote><p><strong>Always use the default (full) export or <code>--scoped</code> for any export intended for migration analysis.</strong></p></blockquote>
<h3>Resume Collection Mode (NEW in v4.3.0)</h3>
<p>
If a previous export was interrupted, timed out, or was run without certain flags (like <code>--rbac</code> or <code>--usage</code>), you can resume and complete the export without starting over.
</p>
<p>
The script extracts the previous archive, inspects what was already collected, skips those data types, and collects only the missing pieces. The output is a new versioned archive (e.g., <code>-v1</code>, <code>-v2</code>).
</p>
<h4>Bash Examples</h4>
<pre><code class="language-bash"># Resume a previous incomplete export
./dma-splunk-cloud-export.sh \
  --stack acme.splunkcloud.com \
  --token &quot;$TOKEN&quot; \
  --resume-collect ./dma_cloud_export_acme-corp_20260115_093000.tar.gz

# Resume AND add RBAC + usage data that were skipped originally
./dma-splunk-cloud-export.sh \
  --stack acme.splunkcloud.com \
  --token &quot;$TOKEN&quot; \
  --resume-collect ./dma_cloud_export_acme-corp_20260115_093000.tar.gz \
  --rbac --usage</code></pre>
<h4>PowerShell Examples</h4>
<pre><code class="language-powershell"># Resume a previous incomplete export
.\dma-splunk-cloud-export.ps1 `
  -Stack &quot;acme.splunkcloud.com&quot; `
  -Token $TOKEN `
  -ResumeCollect &quot;.\dma_cloud_export_acme-corp_20260115_093000.tar.gz&quot;

# Resume AND add RBAC + usage data
.\dma-splunk-cloud-export.ps1 `
  -Stack &quot;acme.splunkcloud.com&quot; `
  -Token $TOKEN `
  -ResumeCollect &quot;.\dma_cloud_export_acme-corp_20260115_093000.tar.gz&quot; `
  -Rbac -Usage</code></pre>
<h4>Versioned Output</h4>
<p>
When resuming, the script creates a versioned archive to avoid overwriting the original:
</p>
<ul>
<li>Original: <code>dma<em>cloud</em>export<em>acme-corp</em>20260115_093000.tar.gz</code></li>
<li>First resume: <code>dma<em>cloud</em>export<em>acme-corp</em>20260115_093000-v1.tar.gz</code></li>
<li>Second resume: <code>dma<em>cloud</em>export<em>acme-corp</em>20260115_093000-v2.tar.gz</code></li>
</ul>
<h4>What Gets Skipped vs Collected</h4>
<table>
<thead>
<tr><th>Data Type</th><th>Skip If...</th></tr>
</thead>
<tbody>
<tr><td>Dashboards</td><td>App already has dashboard files</td></tr>
<tr><td>Saved Searches</td><td>App already has <code>savedsearches.json</code></td></tr>
<tr><td>Knowledge Objects</td><td>App has <code>macros.json</code> + <code>props.json</code> + <code>transforms.json</code></td></tr>
<tr><td>Configs</td><td><code>_configs/</code> directory exists</td></tr>
<tr><td>RBAC</td><td><code>users.json</code> + <code>roles.json</code> exist</td></tr>
<tr><td>Usage Analytics</td><td><code>usage_analytics/</code> has 2+ files</td></tr>
<tr><td>Indexes</td><td><code>indexes.json</code> exists</td></tr>
</tbody>
</table>
<h3>Debug Mode (NEW in v4.1.0)</h3>
<p>
When troubleshooting issues, enable debug mode to capture detailed logs:
</p>
<pre><code class="language-bash">./dma-splunk-cloud-export.sh \
  --stack acme.splunkcloud.com \
  --token &quot;$TOKEN&quot; \
  --apps myapp \
  --debug</code></pre>
<p>
Debug mode provides:
</p>
<ul>
<li><strong>Console output</strong>: Color-coded messages by category (API, SEARCH, TIMING, ERROR, WARN)</li>
<li><strong>Debug log file</strong>: <code>export_debug.log</code> inside the export directory (included in the .tar.gz)</li>
<li><strong>API call tracking</strong>: Every REST API call with HTTP status and response size</li>
<li><strong>Detailed timing</strong>: Duration of each API call and search operation</li>
</ul>
<hr>
<h2>Enterprise Resilience Features</h2>
<p>
<strong>NEW in v4.0.0</strong>: The Cloud script now includes the same enterprise-scale features as the Enterprise script for environments with 4000+ dashboards and 10K+ alerts.
</p>
<h3>Default Settings (Enterprise-Ready)</h3>
<table>
<thead>
<tr><th>Setting</th><th>Default</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>BATCH_SIZE</code></td><td>100</td><td>Items per API request</td></tr>
<tr><td><code>API_TIMEOUT</code></td><td>120s</td><td>Per-request timeout (2 min)</td></tr>
<tr><td><code>MAX_TOTAL_TIME</code></td><td>43200s</td><td>Max runtime (12 hours)</td></tr>
<tr><td><code>MAX_RETRIES</code></td><td>3</td><td>Retry attempts with exponential backoff</td></tr>
<tr><td><code>RATE_LIMIT_DELAY</code></td><td>0.1s</td><td>Delay between API calls (100ms)</td></tr>
<tr><td><code>CHECKPOINT_ENABLED</code></td><td>true</td><td>Enable checkpoint/resume capability</td></tr>
<tr><td><code>RESUME_COLLECT</code></td><td>(none)</td><td>Path to previous .tar.gz for resume collection <strong>(NEW v4.3.0)</strong></td></tr>
</tbody>
</table>
<h3>Checkpoint/Resume Capability</h3>
<p>
If the export is interrupted (timeout, network error, Ctrl+C), you can resume:
</p>
<pre><code class="language-bash"># Script detects previous incomplete export
./dma-splunk-cloud-export.sh

# Output:
# Found checkpoint from 2025-01-06 14:30:00
# Would you like to resume? (Y/n): Y
# Resuming from: Dashboards (offset 500)...</code></pre>
<h3>Export Timing Statistics</h3>
<p>
At completion, the script shows detailed timing:
</p>
<pre><code>╔══════════════════════════════════════════════════════════════════════════╗
║                    EXPORT TIMING STATISTICS                              ║
╠══════════════════════════════════════════════════════════════════════════╣
║  Total Duration:        5 minutes 4 seconds                              ║
║  API Calls:             347                                              ║
║  API Retries:           2                                                ║
║  API Failures:          0                                                ║
║  Rate Limit Hits:       0                                                ║
║  Batches Completed:     52                                               ║
╚══════════════════════════════════════════════════════════════════════════╝</code></pre>
<h3>Environment Variable Overrides</h3>
<p>
For very large Splunk Cloud environments, tune via environment variables:
</p>
<pre><code class="language-bash"># Large environment (5000+ dashboards)
export BATCH_SIZE=50
export API_TIMEOUT=180
./dma-splunk-cloud-export.sh

# Or inline
BATCH_SIZE=50 API_TIMEOUT=180 ./dma-splunk-cloud-export.sh</code></pre>
<hr>
<h2>PowerShell Edition</h2>
<p>
The <code>dma-splunk-cloud-export.ps1</code> script provides the same functionality as the Bash script for Windows environments. It is written in pure PowerShell with zero external dependencies -- no Python, curl, jq, or any other tools are required.
</p>
<h3>Supported PowerShell Versions</h3>
<table>
<thead>
<tr><th>Version</th><th>Platform</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>PowerShell 5.1</td><td>Windows PowerShell (built into Windows 10/11)</td><td>Most common</td></tr>
<tr><td>PowerShell 7+</td><td>Cross-platform (Windows, macOS, Linux)</td><td>Recommended for non-Windows</td></tr>
</tbody>
</table>
<h3>Parameter Equivalence (Bash to PowerShell)</h3>
<table>
<thead>
<tr><th>Bash Flag</th><th>PowerShell Parameter</th><th>Example</th></tr>
</thead>
<tbody>
<tr><td><code>--stack</code></td><td><code>-Stack</code></td><td><code>-Stack "acme.splunkcloud.com"</code></td></tr>
<tr><td><code>--token</code></td><td><code>-Token</code></td><td><code>-Token "xxxxx"</code></td></tr>
<tr><td><code>--user</code></td><td><code>-User</code></td><td><code>-User "admin"</code></td></tr>
<tr><td><code>--password</code></td><td><code>-Password</code></td><td><code>-Password "xxx"</code></td></tr>
<tr><td><code>--apps</code></td><td><code>-Apps</code></td><td><code>-Apps "search,myapp"</code></td></tr>
<tr><td><code>--all-apps</code></td><td><code>-AllApps</code></td><td><code>-AllApps</code></td></tr>
<tr><td><code>--quick</code></td><td><code>-Quick</code></td><td><code>-Quick</code></td></tr>
<tr><td><code>--scoped</code></td><td><code>-Scoped</code></td><td><code>-Scoped</code></td></tr>
<tr><td><code>--rbac</code></td><td><code>-Rbac</code></td><td><code>-Rbac</code></td></tr>
<tr><td><code>--usage</code></td><td><code>-Usage</code></td><td><code>-Usage</code></td></tr>
<tr><td><code>--no-usage</code></td><td><code>-NoUsage</code></td><td><code>-NoUsage</code></td></tr>
<tr><td><code>--resume-collect</code></td><td><code>-ResumeCollect</code></td><td><code>-ResumeCollect ".\previous.tar.gz"</code></td></tr>
<tr><td><code>--proxy</code></td><td><code>-Proxy</code></td><td><code>-Proxy "http://proxy:8080"</code></td></tr>
<tr><td><code>--output</code></td><td><code>-Output</code></td><td><code>-Output "C:\exports"</code></td></tr>
<tr><td><code>--debug</code></td><td><code>-Debug</code></td><td><code>-Debug</code></td></tr>
<tr><td><code>--help</code></td><td><code>-Help</code> or <code>Get-Help</code></td><td><code>Get-Help .\dma-splunk-cloud-export.ps1</code></td></tr>
</tbody>
</table>
<h3>Example Commands</h3>
<pre><code class="language-powershell"># Interactive mode (prompts for all inputs)
.\dma-splunk-cloud-export.ps1

# Non-interactive full export
.\dma-splunk-cloud-export.ps1 -Stack &quot;acme.splunkcloud.com&quot; -Token $env:SPLUNK_TOKEN -AllApps

# Export specific apps with RBAC and usage
.\dma-splunk-cloud-export.ps1 -Stack &quot;acme.splunkcloud.com&quot; -Token $env:SPLUNK_TOKEN -Apps &quot;search,security_app&quot; -Rbac -Usage

# Resume a previous incomplete export
.\dma-splunk-cloud-export.ps1 -Stack &quot;acme.splunkcloud.com&quot; -Token $env:SPLUNK_TOKEN -ResumeCollect &quot;.\previous_export.tar.gz&quot;</code></pre>
<h3>Key Differences from Bash</h3>
<ul>
<li><strong>Zero external dependencies</strong>: Uses <code>Invoke-RestMethod</code> instead of curl, native JSON handling instead of Python/jq</li>
<li><strong>Windows-native tar</strong>: Uses <code>tar.exe</code> built into Windows 10 1803+ for archive creation</li>
<li><strong>PowerShell parameter style</strong>: Uses <code>-ParameterName</code> instead of <code>--flag-name</code></li>
<li><strong>Environment variables</strong>: Use <code>$env:SPLUNK<em>CLOUD</em>TOKEN</code> instead of <code>$SPLUNK<em>CLOUD</em>TOKEN</code></li>
</ul>
<hr>
<h2>Troubleshooting</h2>
<h3>Connection Refused</h3>
<pre><code>Error: curl: (7) Failed to connect to acme-corp.splunkcloud.com port 8089</code></pre>
<p>
<strong>Solutions</strong>:
</p>
<ol>
<li>Check if you're on VPN (if required)</li>
<li>Verify the stack URL is correct</li>
<li>Check corporate firewall rules</li>
<li>Verify Splunk Cloud IP allowlist includes your IP</li>
</ol>
<h3>Authentication Failed (401)</h3>
<pre><code>Error: HTTP 401 Unauthorized</code></pre>
<p>
<strong>Solutions</strong>:
</p>
<ol>
<li>Verify credentials are correct</li>
<li>Check if token has expired</li>
<li>Try creating a new token</li>
<li>Verify user account is active</li>
</ol>
<h3>Forbidden (403)</h3>
<pre><code>Error: HTTP 403 Forbidden for /services/authentication/users</code></pre>
<p>
<strong>Solutions</strong>:
</p>
<ol>
<li>User/token lacks required capabilities</li>
<li>Add <code>admin<em>all</em>objects</code> capability</li>
<li>Check role assignments</li>
<li>Some Cloud stacks restrict certain APIs</li>
</ol>
<h3>Rate Limited (429)</h3>
<pre><code>Error: HTTP 429 Too Many Requests</code></pre>
<p>
<strong>Solutions</strong>:
</p>
<ol>
<li>Script will automatically back off and retry</li>
<li>If persistent, wait 5 minutes and try again</li>
<li>Contact Splunk Cloud support for limit increases</li>
</ol>
<h3>SSL Certificate Error</h3>
<pre><code>Error: SSL certificate problem: unable to get local issuer certificate</code></pre>
<p>
<strong>Solutions</strong>:
</p>
<ol>
<li>Update CA certificates: <code>update-ca-certificates</code></li>
<li>Script uses <code>-k</code> flag as fallback (warns user)</li>
<li>Download Splunk Cloud CA cert and specify</li>
</ol>
<hr>
<h2>Security Best Practices</h2>
<h3>Token Security</h3>
<pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                      TOKEN SECURITY CHECKLIST                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ✓ Use API tokens instead of passwords                                  │
│  ✓ Set appropriate token expiration (7-30 days)                         │
│  ✓ Don&#039;t share tokens in chat, email, or tickets                       │
│  ✓ Use environment variables, not command-line args                    │
│  ✓ Delete token after export is complete                               │
│  ✓ Don&#039;t commit tokens to version control                              │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘</code></pre>
<h3>Export File Security</h3>
<pre><code class="language-bash"># Export file contains sensitive metadata
# Handle with appropriate care

# Secure transfer
scp export.tar.gz user@secure-server:/path/

# Delete after upload to DMA
rm export.tar.gz</code></pre>
<hr>
<h2>What Gets Exported</h2>
<p>
The export creates a <code>.tar.gz</code> file compatible with DMA containing:
</p>
<pre><code>dma_cloud_export_[stack]_[timestamp]/
├── dma-env-summary.md      # Summary report
├── manifest.json                   # Export metadata (schema v4.0)
├── _systeminfo/                    # Server info
├── _rbac/                         # Users and roles
├── _configs/                      # Reconstructed configs
├── _usage_analytics/              # Usage data
└── [app_name]/                    # Per-app data (v2 app-centric structure)
    ├── dashboards/                 # v2: App-scoped dashboards (v4.2.0+)
    │   ├── classic/               # Classic XML dashboards for this app
    │   └── studio/                # Dashboard Studio JSON for this app
    ├── savedsearches.json
    └── macros.json</code></pre>
<hr>
<h2>Comparison with Enterprise Export</h2>
<table>
<thead>
<tr><th>Feature</th><th>Enterprise Export</th><th>Cloud Export</th></tr>
</thead>
<tbody>
<tr><td>Dashboards</td><td>✅ Complete</td><td>✅ Complete</td></tr>
<tr><td>Alerts</td><td>✅ Complete</td><td>✅ Complete</td></tr>
<tr><td>Users/RBAC</td><td>✅ Complete</td><td>✅ Complete</td></tr>
<tr><td>Props/Transforms</td><td>✅ File-based</td><td>⚠️ REST reconstruction</td></tr>
<tr><td>Usage Analytics</td><td>✅ Audit log + search</td><td>⚠️ Search only</td></tr>
<tr><td>Index Stats</td><td>✅ Complete</td><td>⚠️ Limited</td></tr>
<tr><td>Lookup Contents</td><td>✅ Direct file</td><td>✅ REST download</td></tr>
<tr><td>Custom Scripts</td><td>✅ bin/ directory</td><td>❌ Not accessible</td></tr>
<tr><td>Export Format</td><td>.tar.gz</td><td>.tar.gz (compatible)</td></tr>
</tbody>
</table>
<hr>
<h2>Frequently Asked Questions</h2>
<h3>Q: Can I run this on my laptop?</h3>
<p>
<strong>A: Yes!</strong> That's exactly where you should run it. You just need network access to your Splunk Cloud instance.
</p>
<h3>Q: Do I need SSH access to anything?</h3>
<p>
<strong>A: No.</strong> This script is 100% REST API based. No SSH required.
</p>
<h3>Q: Will this work with MFA enabled?</h3>
<p>
<strong>A: Use an API token.</strong> MFA typically doesn't apply to API token authentication.
</p>
<h3>Q: How long does the export take?</h3>
<p>
<strong>A: 5-30 minutes</strong> depending on the size of your environment and network speed. Large environments with many dashboards may take longer.
</p>
<h3>Q: Can I schedule this to run automatically?</h3>
<p>
<strong>A: Yes.</strong> Use the non-interactive mode with environment variables:
</p>
<pre><code class="language-bash">export SPLUNK_CLOUD_STACK=&quot;your-stack.splunkcloud.com&quot;
export SPLUNK_CLOUD_TOKEN=&quot;your-token&quot;
./dma-splunk-cloud-export.sh --all-apps --output /exports/</code></pre>
<h3>Q: Can I run this on Windows?</h3>
<p>
<strong>A: Yes!</strong> Use <code>dma-splunk-cloud-export.ps1</code> which requires only PowerShell 5.1+ and has zero external dependencies. See the <a href="#powershell-edition">PowerShell Edition</a> section for details.
</p>
<h3>Q: My previous export timed out. Do I need to start over?</h3>
<p>
<strong>A: No!</strong> Use <code>--resume-collect</code> (Bash) or <code>-ResumeCollect</code> (PowerShell) to pass your previous <code>.tar.gz</code>. The script will detect what has already been collected and fill in the gaps, creating a new versioned archive (e.g., <code>-v1</code>).
</p>
<pre><code class="language-bash"># Bash
./dma-splunk-cloud-export.sh --stack acme.splunkcloud.com --token &quot;$TOKEN&quot; --resume-collect ./previous_export.tar.gz

# PowerShell
.\dma-splunk-cloud-export.ps1 -Stack &quot;acme.splunkcloud.com&quot; -Token $TOKEN -ResumeCollect &quot;.\previous_export.tar.gz&quot;</code></pre>
<h3>Q: What if I have multiple Splunk Cloud stacks?</h3>
<p>
<strong>A: Run the script once per stack.</strong> Each export will be labeled with the stack name.
</p>
<hr>
<h2>Support</h2>
<p>
If you encounter issues:
</p>
<ol>
<li>Check the troubleshooting section above</li>
<li>Review the export log file generated during the run</li>
<li>Contact the DMA team with:</li>
</ol>
<ul>
<li>Error messages</li>
<li>Stack URL (without credentials)</li>
<li>Splunk Cloud type (Classic/Victoria)</li>
</ul>
<hr>
<h2>What to Expect: Step-by-Step Walkthrough</h2>
<p>
This section shows exactly what you'll see when running the script successfully.
</p>
<h3>Step 1: Launch and Welcome Screen</h3>
<p>
When you run <code>./dma-splunk-cloud-export.sh</code>, you'll see:
</p>
<pre><code>╔══════════════════════════════════════════════════════════════════════════════╗
║                                                                                ║
║  ██████╗ ██╗   ██╗███╗   ██╗ █████╗ ██████╗ ██████╗ ██╗██████╗  ██████╗ ███████╗ ║
║  ██╔══██╗╚██╗ ██╔╝████╗  ██║██╔══██╗██╔══██╗██╔══██╗██║██╔══██╗██╔════╝ ██╔════╝ ║
║  ██║  ██║ ╚████╔╝ ██╔██╗ ██║███████║██████╔╝██████╔╝██║██║  ██║██║  ███╗█████╗   ║
║  ██║  ██║  ╚██╔╝  ██║╚██╗██║██╔══██║██╔══██╗██╔══██╗██║██║  ██║██║   ██║██╔══╝   ║
║  ██████╔╝   ██║   ██║ ╚████║██║  ██║██████╔╝██║  ██║██║██████╔╝╚██████╔╝███████╗ ║
║  ╚═════╝    ╚═╝   ╚═╝  ╚═══╝╚═╝  ╚═╝╚═════╝ ╚═╝  ╚═╝╚═╝╚═════╝  ╚═════╝ ╚══════╝ ║
║                                                                                ║
║                   ☁️  SPLUNK CLOUD EXPORT SCRIPT  ☁️                         ║
║                                                                                ║
║          Complete REST API-Based Data Collection for Migration              ║
║                        Version 4.1.0                                    ║
║                                                                                ║
╚══════════════════════════════════════════════════════════════════════════════╝

Do you want to continue? (Y/n):</code></pre>
<p>
<strong>Action</strong>: Press <code>Y</code> or Enter to continue.
</p>
<h3>Step 2: Pre-Flight Checklist</h3>
<p>
After confirming, you'll see a checklist and system verification:
</p>
<pre><code>╔══════════════════════════════════════════════════════════════════════════════╗
║                     PRE-FLIGHT CHECKLIST                                    ║
║         Please confirm you have the following before continuing            ║
╠══════════════════════════════════════════════════════════════════════════════╣
║                                                                              ║
║  SPLUNK CLOUD ACCESS:                                                      ║
║    □  Splunk Cloud stack URL (e.g., your-company.splunkcloud.com)          ║
║    □  Splunk username with admin privileges                                ║
║    □  Splunk password OR API token (sc_admin role recommended)             ║
║                                                                              ║
║  🔒 DATA PRIVACY &amp; SECURITY:                                                ║
║                                                                              ║
║  We do NOT collect or export:                                              ║
║    ✗  User passwords or password hashes                                    ║
║    ✗  API tokens or session keys                                           ║
║    ✗  Private keys or certificates                                         ║
║    ✗  Your actual log data (only metadata/structure)                       ║
║                                                                              ║
║  We automatically REDACT:                                                  ║
║    ✓  password = [REDACTED] in all .conf files                             ║
║    ✓  secret = [REDACTED] in outputs.conf                                  ║
╚══════════════════════════════════════════════════════════════════════════════╝

  Quick System Check:
    ✓ bash: 5.2.15(1)-release
    ✓ curl: 8.1.2
    ✓ jq: jq-1.6
    ✓ tar: available

Ready to proceed? (Y/n):</code></pre>
<p>
<strong>Action</strong>: Press <code>Y</code> if all checks pass.
</p>
<h3>Step 3: Enter Splunk Cloud Stack URL</h3>
<pre><code>┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 1: SPLUNK CLOUD CONNECTION                                             │
└─────────────────────────────────────────────────────────────────────────────┘

  Your Splunk Cloud stack URL looks like:
    https://your-company.splunkcloud.com

  Enter your Splunk Cloud stack URL: acme-corp.splunkcloud.com

◐ Testing connection to https://acme-corp.splunkcloud.com:8089...
✓ Connection successful</code></pre>
<p>
<strong>Action</strong>: Enter your stack URL (without <code>https://</code> prefix).
</p>
<h3>Step 4: Authentication</h3>
<pre><code>┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 2: AUTHENTICATION                                                      │
└─────────────────────────────────────────────────────────────────────────────┘

  Required Permissions:
    • admin_all_objects - Access all knowledge objects
    • list_users, list_roles - Access RBAC data
    • search - Run analytics queries

  🔒 Security: Your credentials are used locally only and are NEVER stored,
     logged, or transmitted outside of this session. They are cleared on exit.

  Choose authentication method:

    1) API Token (recommended)
    2) Username/Password

  Select option [1]: 1

  Enter API token: ••••••••••••••••••••••••••••••••

◐ Testing authentication...
✓ Token authentication successful (user: admin)</code></pre>
<p>
<strong>Action</strong>: Choose auth method and enter credentials.
</p>
<h3>Step 5: Select Data Categories</h3>
<pre><code>┌─────────────────────────────────────────────────────────────────────────────┐
│ STEP 5: DATA CATEGORIES                                                     │
└─────────────────────────────────────────────────────────────────────────────┘

  Select data categories to collect:

    [✓] 1. Configurations (via REST - reconstructed from API)
    [✓] 2. Dashboards (Classic + Dashboard Studio)
    [✓] 3. Alerts &amp; Saved Searches
    [✓] 4. Users &amp; RBAC (usernames &amp; roles only - NO passwords)
    [✓] 5. Usage Analytics (via search on _audit)
    [✓] 6. Index Statistics
    [✓] 7. Lookup Contents (may be large)
    [ ] 8. Anonymize Data (emails→fake, hosts→fake, IPs→redacted)

  🔒 Privacy: User data includes names/roles only. Passwords are NEVER collected.
  💡 Tip: Enable option 8 when sharing export with third parties.

  Accept defaults? (Y/n): Y</code></pre>
<p>
<strong>Action</strong>: Press <code>Y</code> to accept defaults or <code>n</code> to customize.
</p>
<h3>Step 6: Data Collection Progress</h3>
<pre><code>┌─────────────────────────────────────────────────────────────────────────────┐
│ COLLECTING DATA                                                             │
└─────────────────────────────────────────────────────────────────────────────┘

  [1/7] Collecting system information...
✓ Server info collected
✓ Installed apps collected

  [2/7] Collecting configurations via REST API...
✓ Props configuration collected
✓ Transforms configuration collected
✓ Indexes configuration collected

  [3/7] Collecting dashboards...
[████████████████████████████████████████] 100% security_app/security_overview
✓ Collected 47 Classic dashboards
✓ Collected 12 Dashboard Studio dashboards

  [4/7] Collecting alerts and saved searches...
✓ Collected 89 saved searches (34 alerts)

  [5/7] Collecting users and roles...
✓ Collected 23 users
✓ Collected 8 roles

  [6/7] Collecting usage analytics...
◐ Running search: Dashboard views (last 30 days)...
✓ Dashboard usage collected
◐ Running search: User activity...
✓ User activity collected

  [7/7] Collecting index statistics...
✓ Index stats collected for 15 indexes</code></pre>
<h3>Step 7: Export Complete</h3>
<pre><code>╔══════════════════════════════════════════════════════════════════════════════╗
║                         EXPORT COMPLETE!                                     ║
╠══════════════════════════════════════════════════════════════════════════════╣
║                                                                              ║
║  Export Archive:                                                             ║
║    📦 dma_cloud_export_acme-corp_20241203_143052.tar.gz               ║
║                                                                              ║
║  Summary:                                                                    ║
║    • Dashboards:        59 (47 Classic + 12 Studio)                          ║
║    • Alerts:            34                                                   ║
║    • Saved Searches:    89                                                   ║
║    • Users:             23                                                   ║
║    • Roles:             8                                                    ║
║    • Apps:              12                                                   ║
║    • Indexes:           15                                                   ║
║                                                                              ║
║  Duration: 4 minutes 23 seconds                                              ║
║  Archive Size: 2.3 MB                                                        ║
║                                                                              ║
╠══════════════════════════════════════════════════════════════════════════════╣
║                                                                              ║
║  NEXT STEPS:                                                                 ║
║                                                                              ║
║  1. Upload to DMA:                                                           ║
║     Open Dynatrace Migration Assistant app → Data Sources → Upload Export    ║
║                                                                              ║
║  2. Review the summary report:                                               ║
║     cat dma_cloud_export_acme-corp_20241203_143052/                   ║
║         dma-env-summary.md                                            ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝</code></pre>
<h3>What Success Looks Like</h3>
<p>
After a successful export, you'll have a <code>.tar.gz</code> file. Extract it to see:
</p>
<pre><code class="language-bash">$ tar -tzf dma_cloud_export_acme-corp_20241203_143052.tar.gz | head -20

dma_cloud_export_acme-corp_20241203_143052/
dma_cloud_export_acme-corp_20241203_143052/manifest.json
dma_cloud_export_acme-corp_20241203_143052/dma-env-summary.md
dma_cloud_export_acme-corp_20241203_143052/_export.log
dma_cloud_export_acme-corp_20241203_143052/_systeminfo/
dma_cloud_export_acme-corp_20241203_143052/_systeminfo/server_info.json
dma_cloud_export_acme-corp_20241203_143052/_systeminfo/installed_apps.json
dma_cloud_export_acme-corp_20241203_143052/_rbac/
dma_cloud_export_acme-corp_20241203_143052/_rbac/users.json
dma_cloud_export_acme-corp_20241203_143052/_rbac/roles.json
dma_cloud_export_acme-corp_20241203_143052/_usage_analytics/
dma_cloud_export_acme-corp_20241203_143052/_usage_analytics/dashboard_views.json
dma_cloud_export_acme-corp_20241203_143052/_usage_analytics/users_most_active.json
dma_cloud_export_acme-corp_20241203_143052/security_app/
dma_cloud_export_acme-corp_20241203_143052/security_app/dashboards/
dma_cloud_export_acme-corp_20241203_143052/security_app/savedsearches.json</code></pre>
<h3>If Something Goes Wrong</h3>
<p>
If errors occur, you'll see a warning box:
</p>
<pre><code>╔══════════════════════════════════════════════════════════════════════════════╗
║  ⚠️  EXPORT COMPLETED WITH 3 ERRORS                                          ║
╠══════════════════════════════════════════════════════════════════════════════╣
║                                                                              ║
║  Some data could not be collected. See details below:                        ║
║                                                                              ║
║  Errors:                                                                     ║
║    • HTTP 403: Access denied to /services/data/lookup-table-files           ║
║    • Search timeout: Usage analytics query exceeded 5 minutes               ║
║    • HTTP 429: Rate limited - some data may be incomplete                   ║
║                                                                              ║
║  A troubleshooting report has been generated:                                ║
║    📄 TROUBLESHOOTING.md                                                      ║
║                                                                              ║
╚══════════════════════════════════════════════════════════════════════════════╝</code></pre>
<p>
Review <code>TROUBLESHOOTING.md</code> in the export directory for specific remediation steps.
</p>
<hr>
<h2>Sample Output Files</h2>
<h3>Example: dma-env-summary.md</h3>
<p>
This human-readable summary report is generated in the export directory:
</p>
<pre><code class="language-markdown"># DMA Splunk Cloud Environment Summary

**Export Date**: 2025-12-03 14:30:52 EST
**Export Script Version**: 4.1.0
**Export Type**: Splunk Cloud (REST API)

---

## Environment Overview

| Property | Value |
|----------|-------|
| **Stack URL** | acme-corp.splunkcloud.com |
| **Cloud Type** | Victoria Experience |
| **Splunk Version** | 9.1.3 |
| **Server GUID** | 8F4A2B1C-3D5E-6F7A-8B9C-0D1E2F3A4B5C |

---

## Collection Summary

| Category | Count | Status |
|----------|-------|--------|
| **Applications** | 12 | ✅ Collected |
| **Dashboards** | 59 | ✅ Collected |
| **Alerts** | 34 | ✅ Collected |
| **Users** | 23 | ✅ Collected |
| **Indexes** | 15 | ✅ Collected |

---

## Collection Statistics

| Metric | Value |
|--------|-------|
| **API Calls Made** | 347 |
| **Rate Limit Hits** | 2 |
| **Errors** | 0 |
| **Warnings** | 1 |

---

## Data Categories Collected

- ✅ Configurations (via REST API reconstruction)
- ✅ Dashboards (Classic and Dashboard Studio)
- ✅ Alerts and Saved Searches
- ✅ Users, Roles, and RBAC
- ✅ Usage Analytics (last 30d)
- ✅ Index Statistics
- ⏭️ Lookup Contents (skipped)
- ⏭️ Data Anonymization (available - enable with option 8)

---

## Applications Exported

- search
- security_app
- itsi
- splunk_app_for_aws
- enterprise_security
- phantom
- dashboard_studio
- user-prefs
- learned
- introspection_generator_addon
- alert_manager
- monitoring_console

---

## Cloud Export Notes

This export was collected via REST API from Splunk Cloud. Some differences from Enterprise exports:

1. **Configuration Files**: Reconstructed from REST API endpoints (not direct file access)
2. **Usage Analytics**: Collected via search queries on _audit and _internal indexes
3. **Index Statistics**: Limited to what&#039;s available via REST API
4. **No File System Access**: Cannot access raw bucket data, audit logs, etc.

---

## Errors and Warnings

### Errors (0)
No errors occurred.

### Warnings (1)
- Rate limit approached on dashboard collection; added 2s delay

---

## Next Steps

1. **Upload to DMA**: Upload the `.tar.gz` file to DMA in Dynatrace
2. **Review Dashboards**: Check the dashboard conversion preview
3. **Review Alerts**: Check alert conversion recommendations
4. **Plan Data Ingestion**: Use OpenPipeline templates for log ingestion

---

*Generated by DMA Splunk Cloud Export Script v4.0.0*</code></pre>
<h3>Example: manifest.json (Schema)</h3>
<p>
This machine-readable manifest is used by DMA to process your export:
</p>
<pre><code class="language-json">{
  &quot;schema_version&quot;: &quot;3.3&quot;,
  &quot;export_tool&quot;: &quot;dma-splunk-cloud-export&quot;,
  &quot;export_tool_version&quot;: &quot;4.0.0&quot;,
  &quot;export_timestamp&quot;: &quot;2025-12-03T19:30:52Z&quot;,
  &quot;export_duration_seconds&quot;: 263,

  &quot;source&quot;: {
    &quot;hostname&quot;: &quot;acme-corp.splunkcloud.com&quot;,
    &quot;fqdn&quot;: &quot;acme-corp.splunkcloud.com&quot;,
    &quot;platform&quot;: &quot;Splunk Cloud&quot;,
    &quot;platform_version&quot;: &quot;Victoria Experience&quot;
  },

  &quot;splunk&quot;: {
    &quot;home&quot;: &quot;cloud&quot;,
    &quot;version&quot;: &quot;9.1.3&quot;,
    &quot;build&quot;: &quot;cloud&quot;,
    &quot;flavor&quot;: &quot;cloud&quot;,
    &quot;role&quot;: &quot;search_head&quot;,
    &quot;architecture&quot;: &quot;cloud&quot;,
    &quot;is_cloud&quot;: true,
    &quot;cloud_type&quot;: &quot;Victoria Experience&quot;,
    &quot;server_guid&quot;: &quot;8F4A2B1C-3D5E-6F7A-8B9C-0D1E2F3A4B5C&quot;
  },

  &quot;collection&quot;: {
    &quot;configs&quot;: true,
    &quot;dashboards&quot;: true,
    &quot;alerts&quot;: true,
    &quot;rbac&quot;: true,
    &quot;usage_analytics&quot;: true,
    &quot;usage_period&quot;: &quot;30d&quot;,
    &quot;indexes&quot;: true,
    &quot;lookups&quot;: false
  },

  &quot;statistics&quot;: {
    &quot;apps_exported&quot;: 12,
    &quot;dashboards_classic&quot;: 47,
    &quot;dashboards_studio&quot;: 12,
    &quot;dashboards_total&quot;: 59,
    &quot;alerts&quot;: 34,
    &quot;saved_searches&quot;: 89,
    &quot;users&quot;: 23,
    &quot;roles&quot;: 8,
    &quot;indexes&quot;: 15,
    &quot;api_calls_made&quot;: 347,
    &quot;rate_limit_hits&quot;: 2,
    &quot;errors&quot;: 0,
    &quot;warnings&quot;: 1,
    &quot;total_files&quot;: 234,
    &quot;total_size_bytes&quot;: 2411724
  },

  &quot;apps&quot;: [
    {
      &quot;name&quot;: &quot;security_app&quot;,
      &quot;dashboards&quot;: 15,
      &quot;alerts&quot;: 12,
      &quot;saved_searches&quot;: 28
    },
    {
      &quot;name&quot;: &quot;itsi&quot;,
      &quot;dashboards&quot;: 8,
      &quot;alerts&quot;: 6,
      &quot;saved_searches&quot;: 14
    }
  ],

  &quot;usage_intelligence&quot;: {
    &quot;summary&quot;: {
      &quot;dashboards_never_viewed&quot;: 12,
      &quot;alerts_never_fired&quot;: 8,
      &quot;users_inactive_30d&quot;: 5,
      &quot;alerts_with_failures&quot;: 2
    },
    &quot;volume&quot;: {
      &quot;avg_daily_gb&quot;: 45.7,
      &quot;peak_daily_gb&quot;: 78.3,
      &quot;total_30d_gb&quot;: 1371.2,
      &quot;top_indexes_by_volume&quot;: [
        {&quot;index&quot;: &quot;main&quot;, &quot;total_gb&quot;: 456.2},
        {&quot;index&quot;: &quot;security&quot;, &quot;total_gb&quot;: 312.8},
        {&quot;index&quot;: &quot;web_logs&quot;, &quot;total_gb&quot;: 198.4}
      ],
      &quot;top_sourcetypes_by_volume&quot;: [
        {&quot;sourcetype&quot;: &quot;access_combined&quot;, &quot;total_gb&quot;: 234.5},
        {&quot;sourcetype&quot;: &quot;syslog&quot;, &quot;total_gb&quot;: 187.3}
      ]
    },
    &quot;prioritization&quot;: {
      &quot;top_dashboards&quot;: [
        {&quot;dashboard&quot;: &quot;security_overview&quot;, &quot;views&quot;: 1523},
        {&quot;dashboard&quot;: &quot;executive_summary&quot;, &quot;views&quot;: 892}
      ],
      &quot;top_users&quot;: [
        {&quot;user&quot;: &quot;admin&quot;, &quot;searches&quot;: 4521},
        {&quot;user&quot;: &quot;analyst1&quot;, &quot;searches&quot;: 2134}
      ],
      &quot;top_alerts&quot;: [
        {&quot;alert&quot;: &quot;High CPU Alert&quot;, &quot;fires&quot;: 234},
        {&quot;alert&quot;: &quot;Failed Login&quot;, &quot;fires&quot;: 156}
      ]
    },
    &quot;elimination_candidates&quot;: {
      &quot;dashboards_never_viewed_count&quot;: 12,
      &quot;alerts_never_fired_count&quot;: 8,
      &quot;note&quot;: &quot;See _usage_analytics/ for full lists of candidates&quot;
    }
  }
}</code></pre>
<p>
This manifest enables DMA to:
</p>
<ul>
<li><strong>Prioritize migration</strong> based on actual usage data</li>
<li><strong>Identify elimination candidates</strong> (unused dashboards/alerts)</li>
<li><strong>Estimate data volume</strong> for Dynatrace ingestion planning</li>
<li><strong>Map applications</strong> to their respective assets</li>
</ul>
<hr>
<p>
<em>For Splunk Enterprise (on-premises), use <code>dma-splunk-export.sh</code> instead.</em>
</p>
    </main>

    <footer class="footer">
        <div class="footer-content">
            <div class="footer-logo">Dynatrace Migration Assistant</div>
            <p>Migration intelligence for Splunk to Dynatrace Gen3 Grail</p>
            <div class="footer-links">
                <a href="README-SPLUNK-ENTERPRISE.html">Enterprise Guide</a>
                <a href="README-SPLUNK-CLOUD.html">Cloud Guide</a>
                <a href="SCRIPT-GENERATED-ANALYTICS-REFERENCE.html">Analytics</a>
                <a href="EXPORT-SCHEMA.html">Schema</a>
            </div>
            <p class="footer-copyright">DMA Project &bull; Built for Dynatrace Gen3 Platform</p>
        </div>
    </footer>
</body>
</html>
