# DynaBridge Splunk Cloud Export Script
## Prerequisites Guide for Splunk Cloud (Classic & Victoria Experience)

**Version**: 4.0.1
**Last Updated**: January 2026
**Related Documents**: [Script-Generated Analytics Reference](SCRIPT-GENERATED-ANALYTICS-REFERENCE.md) | [Cloud Export Specification](SPLUNK-CLOUD-EXPORT-SPECIFICATION.md)

---

## Quick Start

```bash
# This script runs from YOUR machine (not on Splunk Cloud)
# You need network access to your Splunk Cloud instance

./dynabridge-splunk-cloud-export.sh
```

---

## How This Differs from Enterprise Export

| Aspect | Enterprise Script | Cloud Script (This One) |
|--------|------------------|-------------------------|
| **Where you run it** | ON the Splunk server | ANYWHERE (your laptop, jump host) |
| **Access method** | SSH + File system | REST API only |
| **What you need** | SSH access + splunk user | Network access + API credentials |
| **File reading** | Reads props.conf, etc. | Reconstructs from REST API |

---

## Prerequisites Checklist

### 1. Network Access

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         NETWORK REQUIREMENTS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Your machine must be able to reach:                                     â”‚
â”‚                                                                          â”‚
â”‚    https://<your-stack>.splunkcloud.com:8089                            â”‚
â”‚                                                                          â”‚
â”‚  This is the Splunk Cloud REST API management port.                     â”‚
â”‚                                                                          â”‚
â”‚  TEST IT:                                                                â”‚
â”‚  $ curl -I https://acme-corp.splunkcloud.com:8089/services/server/info  â”‚
â”‚                                                                          â”‚
â”‚  If this fails, check:                                                   â”‚
â”‚  â€¢ Corporate firewall rules                                              â”‚
â”‚  â€¢ VPN requirements                                                      â”‚
â”‚  â€¢ Splunk Cloud IP allowlist settings                                   â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Splunk Cloud Credentials

You need ONE of the following:

#### Option A: API Token (Recommended)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CREATING AN API TOKEN                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  1. Log into Splunk Cloud web UI                                        â”‚
â”‚     https://your-stack.splunkcloud.com                                  â”‚
â”‚                                                                          â”‚
â”‚  2. Click Settings (gear icon) â†’ Tokens                                 â”‚
â”‚                                                                          â”‚
â”‚  3. Click "New Token"                                                   â”‚
â”‚                                                                          â”‚
â”‚  4. Configure the token:                                                â”‚
â”‚     â€¢ Name: DynaBridge Export Token                                     â”‚
â”‚     â€¢ Expiration: Set appropriate (e.g., 7 days)                        â”‚
â”‚     â€¢ Audience: Search (if asked)                                       â”‚
â”‚                                                                          â”‚
â”‚  5. Copy the token value (shown only once!)                             â”‚
â”‚                                                                          â”‚
â”‚  6. Store it securely - you'll need it for the export script            â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Option B: Username/Password

- Your Splunk Cloud admin username and password
- If MFA is required, you may need to create an API token instead

### 3. Required Permissions

The user or token must have these Splunk capabilities:

| Capability | Required? | What It's Used For |
|------------|-----------|-------------------|
| `admin_all_objects` | **Required** | Access all apps and knowledge objects |
| `list_users` | **Required** | Collect user information |
| `list_roles` | **Required** | Collect role definitions |
| `search` | **Required** | Run usage analytics queries |
| `rest_access` | **Required** | Make REST API calls |
| `list_indexes` | Recommended | Get index metadata |

#### Checking Your Permissions

Run this in Splunk Cloud search:
```spl
| rest /services/authentication/current-context
| table username, roles, capabilities
```

### 4. Local Machine Requirements

| Requirement | Purpose | Check Command |
|-------------|---------|---------------|
| `bash` 4.0+ | Script execution | `bash --version` |
| `curl` | REST API calls | `curl --version` |
| `Python 3` | JSON parsing | `python3 --version` |
| Disk space | Store export | 500MB+ free |

---

## Splunk Cloud Stack URL

### Finding Your Stack URL

Your Splunk Cloud stack URL is the address you use to access Splunk Cloud:

```
https://<stack-name>.splunkcloud.com
```

**Examples**:
- `https://acme-corp.splunkcloud.com`
- `https://mycompany-prod.splunkcloud.com`
- `https://enterprise1.splunkcloud.com`

### Testing Connectivity

```bash
# Test if you can reach the REST API
curl -I "https://your-stack.splunkcloud.com:8089/services/server/info"

# Expected: HTTP/2 401 (Unauthorized - but reachable)
# If you get connection refused or timeout, check network/firewall
```

---

## Supported Splunk Cloud Types

| Cloud Type | Supported | Notes |
|------------|-----------|-------|
| Splunk Cloud Classic | âœ… Yes | Legacy multi-tenant |
| Splunk Cloud Victoria Experience | âœ… Yes | Current default |
| Splunk Cloud on AWS | âœ… Yes | Single-tenant |
| Splunk Cloud on GCP | âœ… Yes | Single-tenant |
| Splunk Cloud on Azure | âœ… Yes | Single-tenant |

---

## What Data Can Be Collected

### âœ… Fully Available via REST API

| Data Type | REST Endpoint | Notes |
|-----------|---------------|-------|
| Dashboards | `/data/ui/views` | Classic + Dashboard Studio |
| Saved Searches | `/saved/searches` | Includes alerts, reports |
| Users | `/authentication/users` | Full user list |
| Roles | `/authorization/roles` | With capabilities |
| Macros | `/admin/macros` | All search macros |
| Eventtypes | `/saved/eventtypes` | Event classifications |
| Tags | `/configs/conf-tags` | Tag assignments |
| Lookup Definitions | `/data/lookup-table-files` | File metadata |
| Lookup Contents | Download via REST | CSV data |
| Field Extractions | `/data/transforms/extractions` | Regex extractions |
| Apps List | `/apps/local` | Installed apps |
| Index Settings | `/data/indexes` | Index configuration |

### âš ï¸ Partially Available

| Data Type | Limitation | Workaround |
|-----------|------------|------------|
| Props.conf | No file access | Reconstructed from `/configs/conf-props` |
| Transforms.conf | No file access | Reconstructed from `/configs/conf-transforms` |
| Usage Analytics | Requires search | Run searches on `_audit` index |
| Index Sizes | Limited stats | Best-effort from API |

### âŒ Not Available

| Data Type | Why | Impact |
|-----------|-----|--------|
| Raw config files | No file system | Use REST reconstruction |
| $SPLUNK_HOME access | Cloud infrastructure | N/A |
| Audit.log file | No file system | Use `_audit` index search |
| License file | Cloud-managed | N/A |
| Deployment apps | Cloud-managed | N/A |

---

## IP Allowlisting (If Required)

Some Splunk Cloud instances require IP allowlisting for API access:

### Check If Required

Contact your Splunk Cloud admin or check:
- Splunk Cloud Admin Config (if you have access)
- Cloud Stack settings

### Adding Your IP

1. Log into Splunk Cloud Admin Config
2. Go to IP Allowlist settings
3. Add your machine's public IP:
   ```bash
   # Find your public IP
   curl ifconfig.me
   ```
4. Allow port 8089 (REST API)

---

## Running the Script

### Basic Usage

```bash
# Make executable
chmod +x dynabridge-splunk-cloud-export.sh

# Run interactively
./dynabridge-splunk-cloud-export.sh
```

### With Pre-set Values

```bash
# Set stack URL via environment
export SPLUNK_CLOUD_STACK="acme-corp.splunkcloud.com"

# Set token via environment (more secure than command line)
export SPLUNK_CLOUD_TOKEN="your-api-token"

./dynabridge-splunk-cloud-export.sh
```

### Non-Interactive Mode (for automation)

```bash
./dynabridge-splunk-cloud-export.sh \
  --stack "acme-corp.splunkcloud.com" \
  --token "$SPLUNK_CLOUD_TOKEN" \
  --all-apps \
  --output /path/to/output
```

---

## Enterprise Resilience Features (v4.0.0)

**NEW in v4.0.0**: The Cloud script now includes the same enterprise-scale features as the Enterprise script for environments with 4000+ dashboards and 10K+ alerts.

### Default Settings (Enterprise-Ready)

| Setting | Default | Description |
|---------|---------|-------------|
| `BATCH_SIZE` | 100 | Items per API request |
| `API_TIMEOUT` | 120s | Per-request timeout (2 min) |
| `MAX_TOTAL_TIME` | 14400s | Max runtime (4 hours) |
| `MAX_RETRIES` | 3 | Retry attempts with exponential backoff |
| `RATE_LIMIT_DELAY` | 0.1s | Delay between API calls (100ms) |
| `CHECKPOINT_ENABLED` | true | Enable checkpoint/resume capability |

### Checkpoint/Resume Capability

If the export is interrupted (timeout, network error, Ctrl+C), you can resume:

```bash
# Script detects previous incomplete export
./dynabridge-splunk-cloud-export.sh

# Output:
# Found checkpoint from 2025-01-06 14:30:00
# Would you like to resume? (Y/n): Y
# Resuming from: Dashboards (offset 500)...
```

### Export Timing Statistics

At completion, the script shows detailed timing:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    EXPORT TIMING STATISTICS                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Total Duration:        5 minutes 4 seconds                              â•‘
â•‘  API Calls:             347                                              â•‘
â•‘  API Retries:           2                                                â•‘
â•‘  API Failures:          0                                                â•‘
â•‘  Rate Limit Hits:       0                                                â•‘
â•‘  Batches Completed:     52                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Environment Variable Overrides

For very large Splunk Cloud environments, tune via environment variables:

```bash
# Large environment (5000+ dashboards)
export BATCH_SIZE=50
export API_TIMEOUT=180
./dynabridge-splunk-cloud-export.sh

# Or inline
BATCH_SIZE=50 API_TIMEOUT=180 ./dynabridge-splunk-cloud-export.sh
```

---

## Troubleshooting

### Connection Refused

```
Error: curl: (7) Failed to connect to acme-corp.splunkcloud.com port 8089
```

**Solutions**:
1. Check if you're on VPN (if required)
2. Verify the stack URL is correct
3. Check corporate firewall rules
4. Verify Splunk Cloud IP allowlist includes your IP

### Authentication Failed (401)

```
Error: HTTP 401 Unauthorized
```

**Solutions**:
1. Verify credentials are correct
2. Check if token has expired
3. Try creating a new token
4. Verify user account is active

### Forbidden (403)

```
Error: HTTP 403 Forbidden for /services/authentication/users
```

**Solutions**:
1. User/token lacks required capabilities
2. Add `admin_all_objects` capability
3. Check role assignments
4. Some Cloud stacks restrict certain APIs

### Rate Limited (429)

```
Error: HTTP 429 Too Many Requests
```

**Solutions**:
1. Script will automatically back off and retry
2. If persistent, wait 5 minutes and try again
3. Contact Splunk Cloud support for limit increases

### SSL Certificate Error

```
Error: SSL certificate problem: unable to get local issuer certificate
```

**Solutions**:
1. Update CA certificates: `update-ca-certificates`
2. Script uses `-k` flag as fallback (warns user)
3. Download Splunk Cloud CA cert and specify

---

## Security Best Practices

### Token Security

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      TOKEN SECURITY CHECKLIST                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  âœ“ Use API tokens instead of passwords                                  â”‚
â”‚  âœ“ Set appropriate token expiration (7-30 days)                         â”‚
â”‚  âœ“ Don't share tokens in chat, email, or tickets                       â”‚
â”‚  âœ“ Use environment variables, not command-line args                    â”‚
â”‚  âœ“ Delete token after export is complete                               â”‚
â”‚  âœ“ Don't commit tokens to version control                              â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Export File Security

```bash
# Export file contains sensitive metadata
# Handle with appropriate care

# Secure transfer
scp export.tar.gz user@secure-server:/path/

# Delete after upload to DynaBridge
rm export.tar.gz
```

---

## What Gets Exported

The export creates a `.tar.gz` file compatible with DynaBridge containing:

```
dynabridge_cloud_export_[stack]_[timestamp]/
â”œâ”€â”€ dynasplunk-env-summary.md      # Summary report
â”œâ”€â”€ _metadata.json                  # Export metadata
â”œâ”€â”€ _systeminfo/                    # Server info
â”œâ”€â”€ _rbac/                         # Users and roles
â”œâ”€â”€ _configs/                      # Reconstructed configs
â”œâ”€â”€ _usage_analytics/              # Usage data
â”œâ”€â”€ [app_name]/                    # Per-app data
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ savedsearches.json
â”‚   â””â”€â”€ macros.json
â””â”€â”€ dashboard_studio/              # Dashboard Studio content
```

---

## Comparison with Enterprise Export

| Feature | Enterprise Export | Cloud Export |
|---------|------------------|--------------|
| Dashboards | âœ… Complete | âœ… Complete |
| Alerts | âœ… Complete | âœ… Complete |
| Users/RBAC | âœ… Complete | âœ… Complete |
| Props/Transforms | âœ… File-based | âš ï¸ REST reconstruction |
| Usage Analytics | âœ… Audit log + search | âš ï¸ Search only |
| Index Stats | âœ… Complete | âš ï¸ Limited |
| Lookup Contents | âœ… Direct file | âœ… REST download |
| Custom Scripts | âœ… bin/ directory | âŒ Not accessible |
| Export Format | .tar.gz | .tar.gz (compatible) |

---

## Frequently Asked Questions

### Q: Can I run this on my laptop?

**A: Yes!** That's exactly where you should run it. You just need network access to your Splunk Cloud instance.

### Q: Do I need SSH access to anything?

**A: No.** This script is 100% REST API based. No SSH required.

### Q: Will this work with MFA enabled?

**A: Use an API token.** MFA typically doesn't apply to API token authentication.

### Q: How long does the export take?

**A: 5-30 minutes** depending on the size of your environment and network speed. Large environments with many dashboards may take longer.

### Q: Can I schedule this to run automatically?

**A: Yes.** Use the non-interactive mode with environment variables:
```bash
export SPLUNK_CLOUD_STACK="your-stack.splunkcloud.com"
export SPLUNK_CLOUD_TOKEN="your-token"
./dynabridge-splunk-cloud-export.sh --all-apps --output /exports/
```

### Q: What if I have multiple Splunk Cloud stacks?

**A: Run the script once per stack.** Each export will be labeled with the stack name.

---

## Support

If you encounter issues:

1. Check the troubleshooting section above
2. Review the export log file generated during the run
3. Contact the DynaBridge team with:
   - Error messages
   - Stack URL (without credentials)
   - Splunk Cloud type (Classic/Victoria)

---

## What to Expect: Step-by-Step Walkthrough

This section shows exactly what you'll see when running the script successfully.

### Step 1: Launch and Welcome Screen

When you run `./dynabridge-splunk-cloud-export.sh`, you'll see:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                â•‘
â•‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â•‘
â•‘  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â•â•â• â•‘
â•‘  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•‘
â•‘  â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘  â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•   â•‘
â•‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â•‘
â•‘  â•šâ•â•â•â•â•â•    â•šâ•â•   â•šâ•â•  â•šâ•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â• â•‘
â•‘                                                                                â•‘
â•‘                   â˜ï¸  SPLUNK CLOUD EXPORT SCRIPT  â˜ï¸                         â•‘
â•‘                                                                                â•‘
â•‘          Complete REST API-Based Data Collection for Migration              â•‘
â•‘                        Version 4.0.0                                    â•‘
â•‘                                                                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Do you want to continue? (Y/n):
```

**Action**: Press `Y` or Enter to continue.

### Step 2: Pre-Flight Checklist

After confirming, you'll see a checklist and system verification:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     PRE-FLIGHT CHECKLIST                                    â•‘
â•‘         Please confirm you have the following before continuing            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  SPLUNK CLOUD ACCESS:                                                      â•‘
â•‘    â–¡  Splunk Cloud stack URL (e.g., your-company.splunkcloud.com)          â•‘
â•‘    â–¡  Splunk username with admin privileges                                â•‘
â•‘    â–¡  Splunk password OR API token (sc_admin role recommended)             â•‘
â•‘                                                                              â•‘
â•‘  ğŸ”’ DATA PRIVACY & SECURITY:                                                â•‘
â•‘                                                                              â•‘
â•‘  We do NOT collect or export:                                              â•‘
â•‘    âœ—  User passwords or password hashes                                    â•‘
â•‘    âœ—  API tokens or session keys                                           â•‘
â•‘    âœ—  Private keys or certificates                                         â•‘
â•‘    âœ—  Your actual log data (only metadata/structure)                       â•‘
â•‘                                                                              â•‘
â•‘  We automatically REDACT:                                                  â•‘
â•‘    âœ“  password = [REDACTED] in all .conf files                             â•‘
â•‘    âœ“  secret = [REDACTED] in outputs.conf                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Quick System Check:
    âœ“ bash: 5.2.15(1)-release
    âœ“ curl: 8.1.2
    âœ“ jq: jq-1.6
    âœ“ tar: available

Ready to proceed? (Y/n):
```

**Action**: Press `Y` if all checks pass.

### Step 3: Enter Splunk Cloud Stack URL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: SPLUNK CLOUD CONNECTION                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Your Splunk Cloud stack URL looks like:
    https://your-company.splunkcloud.com

  Enter your Splunk Cloud stack URL: acme-corp.splunkcloud.com

â— Testing connection to https://acme-corp.splunkcloud.com:8089...
âœ“ Connection successful
```

**Action**: Enter your stack URL (without `https://` prefix).

### Step 4: Authentication

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: AUTHENTICATION                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Required Permissions:
    â€¢ admin_all_objects - Access all knowledge objects
    â€¢ list_users, list_roles - Access RBAC data
    â€¢ search - Run analytics queries

  ğŸ”’ Security: Your credentials are used locally only and are NEVER stored,
     logged, or transmitted outside of this session. They are cleared on exit.

  Choose authentication method:

    1) API Token (recommended)
    2) Username/Password

  Select option [1]: 1

  Enter API token: â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢

â— Testing authentication...
âœ“ Token authentication successful (user: admin)
```

**Action**: Choose auth method and enter credentials.

### Step 5: Select Data Categories

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: DATA CATEGORIES                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Select data categories to collect:

    [âœ“] 1. Configurations (via REST - reconstructed from API)
    [âœ“] 2. Dashboards (Classic + Dashboard Studio)
    [âœ“] 3. Alerts & Saved Searches
    [âœ“] 4. Users & RBAC (usernames & roles only - NO passwords)
    [âœ“] 5. Usage Analytics (via search on _audit)
    [âœ“] 6. Index Statistics
    [âœ“] 7. Lookup Contents (may be large)
    [ ] 8. Anonymize Data (emailsâ†’fake, hostsâ†’fake, IPsâ†’redacted)

  ğŸ”’ Privacy: User data includes names/roles only. Passwords are NEVER collected.
  ğŸ’¡ Tip: Enable option 8 when sharing export with third parties.

  Accept defaults? (Y/n): Y
```

**Action**: Press `Y` to accept defaults or `n` to customize.

### Step 6: Data Collection Progress

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ COLLECTING DATA                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  [1/7] Collecting system information...
âœ“ Server info collected
âœ“ Installed apps collected

  [2/7] Collecting configurations via REST API...
âœ“ Props configuration collected
âœ“ Transforms configuration collected
âœ“ Indexes configuration collected

  [3/7] Collecting dashboards...
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% security_app/security_overview
âœ“ Collected 47 Classic dashboards
âœ“ Collected 12 Dashboard Studio dashboards

  [4/7] Collecting alerts and saved searches...
âœ“ Collected 89 saved searches (34 alerts)

  [5/7] Collecting users and roles...
âœ“ Collected 23 users
âœ“ Collected 8 roles

  [6/7] Collecting usage analytics...
â— Running search: Dashboard views (last 30 days)...
âœ“ Dashboard usage collected
â— Running search: User activity...
âœ“ User activity collected

  [7/7] Collecting index statistics...
âœ“ Index stats collected for 15 indexes
```

### Step 7: Export Complete

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         EXPORT COMPLETE!                                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  Export Archive:                                                             â•‘
â•‘    ğŸ“¦ dynabridge_cloud_export_acme-corp_20241203_143052.tar.gz               â•‘
â•‘                                                                              â•‘
â•‘  Summary:                                                                    â•‘
â•‘    â€¢ Dashboards:        59 (47 Classic + 12 Studio)                          â•‘
â•‘    â€¢ Alerts:            34                                                   â•‘
â•‘    â€¢ Saved Searches:    89                                                   â•‘
â•‘    â€¢ Users:             23                                                   â•‘
â•‘    â€¢ Roles:             8                                                    â•‘
â•‘    â€¢ Apps:              12                                                   â•‘
â•‘    â€¢ Indexes:           15                                                   â•‘
â•‘                                                                              â•‘
â•‘  Duration: 4 minutes 23 seconds                                              â•‘
â•‘  Archive Size: 2.3 MB                                                        â•‘
â•‘                                                                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  NEXT STEPS:                                                                 â•‘
â•‘                                                                              â•‘
â•‘  1. Upload to DynaBridge:                                                    â•‘
â•‘     Open DynaBridge for Splunk app â†’ Data Sources â†’ Upload Export            â•‘
â•‘                                                                              â•‘
â•‘  2. Review the summary report:                                               â•‘
â•‘     cat dynabridge_cloud_export_acme-corp_20241203_143052/                   â•‘
â•‘         dynasplunk-env-summary.md                                            â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### What Success Looks Like

After a successful export, you'll have a `.tar.gz` file. Extract it to see:

```bash
$ tar -tzf dynabridge_cloud_export_acme-corp_20241203_143052.tar.gz | head -20

dynabridge_cloud_export_acme-corp_20241203_143052/
dynabridge_cloud_export_acme-corp_20241203_143052/manifest.json
dynabridge_cloud_export_acme-corp_20241203_143052/dynasplunk-env-summary.md
dynabridge_cloud_export_acme-corp_20241203_143052/_export.log
dynabridge_cloud_export_acme-corp_20241203_143052/_systeminfo/
dynabridge_cloud_export_acme-corp_20241203_143052/_systeminfo/server_info.json
dynabridge_cloud_export_acme-corp_20241203_143052/_systeminfo/installed_apps.json
dynabridge_cloud_export_acme-corp_20241203_143052/_rbac/
dynabridge_cloud_export_acme-corp_20241203_143052/_rbac/users.json
dynabridge_cloud_export_acme-corp_20241203_143052/_rbac/roles.json
dynabridge_cloud_export_acme-corp_20241203_143052/_usage_analytics/
dynabridge_cloud_export_acme-corp_20241203_143052/_usage_analytics/dashboard_views.json
dynabridge_cloud_export_acme-corp_20241203_143052/_usage_analytics/users_most_active.json
dynabridge_cloud_export_acme-corp_20241203_143052/security_app/
dynabridge_cloud_export_acme-corp_20241203_143052/security_app/dashboards/
dynabridge_cloud_export_acme-corp_20241203_143052/security_app/savedsearches.json
```

### If Something Goes Wrong

If errors occur, you'll see a warning box:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âš ï¸  EXPORT COMPLETED WITH 3 ERRORS                                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  Some data could not be collected. See details below:                        â•‘
â•‘                                                                              â•‘
â•‘  Errors:                                                                     â•‘
â•‘    â€¢ HTTP 403: Access denied to /services/data/lookup-table-files           â•‘
â•‘    â€¢ Search timeout: Usage analytics query exceeded 5 minutes               â•‘
â•‘    â€¢ HTTP 429: Rate limited - some data may be incomplete                   â•‘
â•‘                                                                              â•‘
â•‘  A troubleshooting report has been generated:                                â•‘
â•‘    ğŸ“„ TROUBLESHOOTING.md                                                      â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

Review `TROUBLESHOOTING.md` in the export directory for specific remediation steps.

---

## Sample Output Files

### Example: dynasplunk-env-summary.md

This human-readable summary report is generated in the export directory:

```markdown
# DynaBridge Splunk Cloud Environment Summary

**Export Date**: 2025-12-03 14:30:52 EST
**Export Script Version**: 4.0.0
**Export Type**: Splunk Cloud (REST API)

---

## Environment Overview

| Property | Value |
|----------|-------|
| **Stack URL** | acme-corp.splunkcloud.com |
| **Cloud Type** | Victoria Experience |
| **Splunk Version** | 9.1.3 |
| **Server GUID** | 8F4A2B1C-3D5E-6F7A-8B9C-0D1E2F3A4B5C |

---

## Collection Summary

| Category | Count | Status |
|----------|-------|--------|
| **Applications** | 12 | âœ… Collected |
| **Dashboards** | 59 | âœ… Collected |
| **Alerts** | 34 | âœ… Collected |
| **Users** | 23 | âœ… Collected |
| **Indexes** | 15 | âœ… Collected |

---

## Collection Statistics

| Metric | Value |
|--------|-------|
| **API Calls Made** | 347 |
| **Rate Limit Hits** | 2 |
| **Errors** | 0 |
| **Warnings** | 1 |

---

## Data Categories Collected

- âœ… Configurations (via REST API reconstruction)
- âœ… Dashboards (Classic and Dashboard Studio)
- âœ… Alerts and Saved Searches
- âœ… Users, Roles, and RBAC
- âœ… Usage Analytics (last 30d)
- âœ… Index Statistics
- â­ï¸ Lookup Contents (skipped)
- â­ï¸ Data Anonymization (available - enable with option 8)

---

## Applications Exported

- search
- security_app
- itsi
- splunk_app_for_aws
- enterprise_security
- phantom
- dashboard_studio
- user-prefs
- learned
- introspection_generator_addon
- alert_manager
- monitoring_console

---

## Cloud Export Notes

This export was collected via REST API from Splunk Cloud. Some differences from Enterprise exports:

1. **Configuration Files**: Reconstructed from REST API endpoints (not direct file access)
2. **Usage Analytics**: Collected via search queries on _audit and _internal indexes
3. **Index Statistics**: Limited to what's available via REST API
4. **No File System Access**: Cannot access raw bucket data, audit logs, etc.

---

## Errors and Warnings

### Errors (0)
No errors occurred.

### Warnings (1)
- Rate limit approached on dashboard collection; added 2s delay

---

## Next Steps

1. **Upload to DynaBridge**: Upload the `.tar.gz` file to DynaBridge in Dynatrace
2. **Review Dashboards**: Check the dashboard conversion preview
3. **Review Alerts**: Check alert conversion recommendations
4. **Plan Data Ingestion**: Use OpenPipeline templates for log ingestion

---

*Generated by DynaBridge Splunk Cloud Export Script v4.0.0*
```

### Example: manifest.json (Schema)

This machine-readable manifest is used by DynaBridge to process your export:

```json
{
  "schema_version": "3.3",
  "export_tool": "dynabridge-splunk-cloud-export",
  "export_tool_version": "4.0.0",
  "export_timestamp": "2025-12-03T19:30:52Z",
  "export_duration_seconds": 263,

  "source": {
    "hostname": "acme-corp.splunkcloud.com",
    "fqdn": "acme-corp.splunkcloud.com",
    "platform": "Splunk Cloud",
    "platform_version": "Victoria Experience"
  },

  "splunk": {
    "home": "cloud",
    "version": "9.1.3",
    "build": "cloud",
    "flavor": "cloud",
    "role": "search_head",
    "architecture": "cloud",
    "is_cloud": true,
    "cloud_type": "Victoria Experience",
    "server_guid": "8F4A2B1C-3D5E-6F7A-8B9C-0D1E2F3A4B5C"
  },

  "collection": {
    "configs": true,
    "dashboards": true,
    "alerts": true,
    "rbac": true,
    "usage_analytics": true,
    "usage_period": "30d",
    "indexes": true,
    "lookups": false
  },

  "statistics": {
    "apps_exported": 12,
    "dashboards_classic": 47,
    "dashboards_studio": 12,
    "dashboards_total": 59,
    "alerts": 34,
    "saved_searches": 89,
    "users": 23,
    "roles": 8,
    "indexes": 15,
    "api_calls_made": 347,
    "rate_limit_hits": 2,
    "errors": 0,
    "warnings": 1,
    "total_files": 234,
    "total_size_bytes": 2411724
  },

  "apps": [
    {
      "name": "security_app",
      "dashboards": 15,
      "alerts": 12,
      "saved_searches": 28
    },
    {
      "name": "itsi",
      "dashboards": 8,
      "alerts": 6,
      "saved_searches": 14
    }
  ],

  "usage_intelligence": {
    "summary": {
      "dashboards_never_viewed": 12,
      "alerts_never_fired": 8,
      "users_inactive_30d": 5,
      "alerts_with_failures": 2
    },
    "volume": {
      "avg_daily_gb": 45.7,
      "peak_daily_gb": 78.3,
      "total_30d_gb": 1371.2,
      "top_indexes_by_volume": [
        {"index": "main", "total_gb": 456.2},
        {"index": "security", "total_gb": 312.8},
        {"index": "web_logs", "total_gb": 198.4}
      ],
      "top_sourcetypes_by_volume": [
        {"sourcetype": "access_combined", "total_gb": 234.5},
        {"sourcetype": "syslog", "total_gb": 187.3}
      ]
    },
    "prioritization": {
      "top_dashboards": [
        {"dashboard": "security_overview", "views": 1523},
        {"dashboard": "executive_summary", "views": 892}
      ],
      "top_users": [
        {"user": "admin", "searches": 4521},
        {"user": "analyst1", "searches": 2134}
      ],
      "top_alerts": [
        {"alert": "High CPU Alert", "fires": 234},
        {"alert": "Failed Login", "fires": 156}
      ]
    },
    "elimination_candidates": {
      "dashboards_never_viewed_count": 12,
      "alerts_never_fired_count": 8,
      "note": "See _usage_analytics/ for full lists of candidates"
    }
  }
}
```

This manifest enables DynaBridge to:
- **Prioritize migration** based on actual usage data
- **Identify elimination candidates** (unused dashboards/alerts)
- **Estimate data volume** for Dynatrace ingestion planning
- **Map applications** to their respective assets

---

*For Splunk Enterprise (on-premises), use `dynabridge-splunk-export.sh` instead.*
