<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DynaBridge Script Analytics Reference | DynaBridge for Splunk</title>
    <style>
        :root {
            --db-header-bg: #14172b;
            --db-nav-dark: #1a1d2e;
            --db-accent-purple: #7c5dc7;
            --db-accent-blue: #4da6e8;
            --db-accent-green: #6abf4b;
            --content-bg: #ffffff;
            --content-card: #f8f9fa;
            --text-dark: #1a1a2e;
            --text-body: #3a3a4a;
            --text-muted: #6c757d;
            --text-light: #ffffff;
            --accent-blue: #1456ff;
            --success: #6abf4b;
            --border-light: #e0e0e0;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Arial, sans-serif;
            line-height: 1.45;
            color: var(--text-dark);
            background: var(--content-bg);
            font-size: 14px;
        }

        /* Header - Compact */
        .header-banner {
            background: var(--db-header-bg);
            padding: 20px 16px;
            text-align: center;
        }
        .header-content { max-width: 900px; margin: 0 auto; }
        .logo-container {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 12px;
            margin-bottom: 8px;
        }
        .logo-image { height: 36px; width: 36px; object-fit: contain; }
        .logo-text { font-size: 1.5em; font-weight: 700; color: var(--text-light); }
        .logo-text .highlight { color: var(--db-accent-purple); }
        .header-tagline {
            color: rgba(255,255,255,0.6);
            font-size: 0.85em;
            margin-bottom: 10px;
        }
        .version-badge {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            background: rgba(255,255,255,0.08);
            border: 1px solid rgba(255,255,255,0.15);
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.75em;
            color: rgba(255,255,255,0.7);
        }
        .version-badge .dot { width: 5px; height: 5px; background: var(--success); border-radius: 50%; }
        .doc-title { margin-top: 12px; padding-top: 10px; border-top: 1px solid rgba(255,255,255,0.1); }
        .doc-title h2 { color: var(--text-light); font-size: 1.1em; font-weight: 600; margin: 0; padding: 0; border: none; }

        /* Navigation - Compact */
        .doc-nav {
            background: var(--db-nav-dark);
            position: sticky;
            top: 0;
            z-index: 100;
            border-bottom: 1px solid rgba(255,255,255,0.05);
        }
        .doc-nav-inner { max-width: 1100px; margin: 0 auto; display: flex; flex-wrap: wrap; justify-content: center; }
        .doc-nav a {
            color: rgba(255,255,255,0.55);
            text-decoration: none;
            font-size: 0.78em;
            font-weight: 500;
            padding: 10px 14px;
            border-bottom: 2px solid transparent;
            transition: all 0.15s;
        }
        .doc-nav a:hover { color: var(--text-light); background: rgba(255,255,255,0.05); border-bottom-color: var(--db-accent-purple); }

        /* Content - Tight */
        .content { max-width: 900px; margin: 0 auto; padding: 20px 24px 30px; }

        /* Typography - Compact */
        h1 {
            color: var(--text-dark);
            font-size: 1.6em;
            font-weight: 700;
            margin-bottom: 4px;
            padding-bottom: 8px;
            border-bottom: 2px solid var(--db-accent-purple);
        }
        h2 {
            color: var(--text-dark);
            font-size: 1.25em;
            font-weight: 600;
            margin-top: 20px;
            margin-bottom: 6px;
            padding-bottom: 4px;
            border-bottom: 1px solid var(--border-light);
        }
        h3 {
            color: var(--text-dark);
            font-size: 1.05em;
            font-weight: 600;
            margin-top: 14px;
            margin-bottom: 4px;
        }
        h4 {
            color: var(--text-dark);
            font-size: 0.95em;
            font-weight: 600;
            margin-top: 10px;
            margin-bottom: 3px;
        }
        h5, h6 {
            color: var(--text-dark);
            font-size: 0.9em;
            font-weight: 600;
            margin-top: 8px;
            margin-bottom: 2px;
        }
        p { margin-bottom: 8px; color: var(--text-body); }
        strong { color: var(--text-dark); font-weight: 600; }
        a { color: var(--accent-blue); text-decoration: none; }
        a:hover { text-decoration: underline; }

        /* Code - Compact */
        pre {
            background: #1e1e2e;
            border: 1px solid #2d2d3d;
            border-radius: 4px;
            padding: 10px 12px;
            overflow-x: auto;
            margin: 8px 0;
            font-family: 'SF Mono', Monaco, Consolas, monospace;
            font-size: 0.82em;
            line-height: 1.4;
            color: #e0e0e0;
        }
        code {
            background: #f0f0f2;
            color: #c7254e;
            padding: 1px 4px;
            border-radius: 3px;
            font-family: 'SF Mono', Monaco, Consolas, monospace;
            font-size: 0.85em;
        }
        pre code { background: none; padding: 0; color: #e0e0e0; }

        /* Tables - Compact */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 10px 0;
            font-size: 0.88em;
            border: 1px solid var(--border-light);
        }
        th {
            background: var(--db-nav-dark);
            color: var(--text-light);
            padding: 8px 10px;
            text-align: left;
            font-weight: 600;
            font-size: 0.8em;
            text-transform: uppercase;
            letter-spacing: 0.02em;
        }
        td {
            padding: 7px 10px;
            border-bottom: 1px solid var(--border-light);
            color: var(--text-body);
        }
        tr:last-child td { border-bottom: none; }
        tr:nth-child(even) td { background: #f9f9fb; }

        /* Lists - Tight */
        ul, ol { margin: 6px 0; padding-left: 20px; color: var(--text-body); }
        li { margin-bottom: 2px; }
        li::marker { color: var(--db-accent-purple); }

        /* Blockquotes */
        blockquote {
            background: var(--content-card);
            border-left: 3px solid var(--db-accent-purple);
            border-radius: 0 4px 4px 0;
            padding: 8px 12px;
            margin: 10px 0;
        }
        blockquote p { margin-bottom: 0; }

        /* HR - Minimal */
        hr { border: none; border-top: 1px solid var(--border-light); margin: 16px 0; }

        /* Footer - Compact */
        .footer { background: var(--db-nav-dark); padding: 20px 16px; text-align: center; }
        .footer-content { max-width: 600px; margin: 0 auto; }
        .footer-logo { font-size: 1em; font-weight: 700; color: var(--text-light); margin-bottom: 6px; }
        .footer-logo .highlight { color: var(--db-accent-purple); }
        .footer p { color: rgba(255,255,255,0.5); font-size: 0.8em; margin-bottom: 4px; }
        .footer-links { display: flex; justify-content: center; gap: 16px; margin-top: 10px; flex-wrap: wrap; }
        .footer-links a { color: rgba(255,255,255,0.45); font-size: 0.75em; }
        .footer-links a:hover { color: var(--db-accent-purple); text-decoration: none; }
        .footer-copyright {
            margin-top: 12px;
            padding-top: 10px;
            border-top: 1px solid rgba(255,255,255,0.08);
            font-size: 0.7em;
            color: rgba(255,255,255,0.35);
        }

        /* Print */
        @media print {
            .doc-nav, .footer { display: none; }
            .content { max-width: 100%; padding: 12px; }
            .header-banner { padding: 12px; }
        }

        /* Responsive */
        @media (max-width: 768px) {
            .header-banner { padding: 16px 12px; }
            .logo-text { font-size: 1.2em; }
            .logo-image { height: 28px; width: 28px; }
            .content { padding: 16px 12px; }
            h1 { font-size: 1.4em; }
            h2 { font-size: 1.15em; }
            table { font-size: 0.82em; }
            th, td { padding: 6px 8px; }
            .doc-nav a { padding: 8px 10px; font-size: 0.72em; }
        }
    </style>
</head>
<body>
    <header class="header-banner">
        <div class="header-content">
            <div class="logo-container">
                <img class="logo-image" src="dynabridge-symbol.png" alt="DynaBridge" onerror="this.style.display='none'" />
                <div class="logo-text"><span class="highlight">Dyna</span>Bridge for Splunk</div>
            </div>
            <p class="header-tagline">Migration Intelligence Platform for Splunk to Dynatrace</p>
            <span class="version-badge"><span class="dot"></span>Version 4.0.1</span>
            <div class="doc-title"><h2>DynaBridge Script Analytics Reference</h2></div>
        </div>
    </header>

    <nav class="doc-nav">
        <div class="doc-nav-inner">
            <a href="README-SPLUNK-ENTERPRISE.html">Enterprise README</a>
            <a href="README-SPLUNK-CLOUD.html">Cloud README</a>
            <a href="SPLUNK-ENTERPRISE-EXPORT-SPECIFICATION.html">Enterprise Spec</a>
            <a href="SPLUNK-CLOUD-EXPORT-SPECIFICATION.html">Cloud Spec</a>
            <a href="SCRIPT-GENERATED-ANALYTICS-REFERENCE.html">Analytics Reference</a>
            <a href="EXPORT-SCHEMA.html">Export Schema</a>
        </div>
    </nav>

    <main class="content">
<h1>Script-Generated Analytics Reference</h1>
<h2>DynaBridge Splunk Export - Complete Analytics File Reference</h2>
<p>
<strong>Applies To</strong>: Splunk Enterprise & Splunk Cloud Export Scripts
<strong>Version</strong>: 4.0.1 (Enterprise) / 4.0.1 (Cloud)
<strong>Last Updated</strong>: January 2026
</p>
<hr>
<h2>Executive Summary</h2>
<p>
The DynaBridge Splunk Export Scripts generate <strong>migration intelligence files</strong> by running SPL queries against Splunk's internal indexes (<code><em>audit</code>, <code></em>internal</code>). These files provide insights that <strong>do not exist natively in Splunk</strong> and are specifically designed to support data-driven migration decisions.
</p>
<h3>Key Value Proposition</h3>
<table>
<thead>
<tr><th>What Splunk Provides</th><th>What DynaBridge Generates</th></tr>
</thead>
<tbody>
<tr><td>Raw configurations</td><td><strong>Migration prioritization scores</strong></td></tr>
<tr><td>Dashboard definitions</td><td><strong>Dashboard usage analytics</strong> (who views what, how often)</td></tr>
<tr><td>Alert configurations</td><td><strong>Alert effectiveness metrics</strong> (which fire, which don't)</td></tr>
<tr><td>User accounts</td><td><strong>User activity intelligence</strong> (who's active, who's not)</td></tr>
<tr><td>Index definitions</td><td><strong>Volume trends and capacity planning data</strong></td></tr>
</tbody>
</table>
<hr>
<h2>Enterprise vs. Cloud: Key Differences</h2>
<p>
Both the <strong>Enterprise</strong> and <strong>Cloud</strong> export scripts generate the <strong>same ~47 analytics files</strong>. However, there are important differences in how data is collected and potential limitations:
</p>
<h3>Comparison Matrix</h3>
<table>
<thead>
<tr><th>Aspect</th><th>Enterprise Script</th><th>Cloud Script</th></tr>
</thead>
<tbody>
<tr><td><strong>Script File</strong></td><td><code>dynabridge-splunk-export.sh</code></td><td><code>dynabridge-splunk-cloud-export.sh</code></td></tr>
<tr><td><strong>Access Method</strong></td><td>File system + REST API</td><td>REST API only</td></tr>
<tr><td><strong>Run Location</strong></td><td>On the Splunk server</td><td>Any machine with network access</td></tr>
<tr><td><strong>Authentication</strong></td><td>Username/password</td><td>API Token (recommended) or username/password</td></tr>
<tr><td><strong><code>_audit</code> Index Access</strong></td><td>Full access</td><td>May be restricted (Classic Experience)</td></tr>
<tr><td><strong><code>_internal</code> Index Access</strong></td><td>Full access</td><td>May be restricted</td></tr>
<tr><td><strong>File System Exports</strong></td><td>Yes (<code>.conf</code> files, XML dashboards)</td><td>No (REST API only)</td></tr>
<tr><td><strong>Expected Success Rate</strong></td><td>~95-100% of analytics files</td><td>~70-90% (varies by Cloud tier/config)</td></tr>
</tbody>
</table>
<h3>Cloud-Specific Limitations</h3>
<p>
Splunk Cloud environments may have restricted access to internal indexes. The following analytics categories are most likely to be affected:
</p>
<table>
<thead>
<tr><th>Category</th><th>Risk Level</th><th>Reason</th></tr>
</thead>
<tbody>
<tr><td><strong>Dashboard View Analytics</strong></td><td>ðŸŸ¡ Medium</td><td>Requires <code>_audit</code> index access</td></tr>
<tr><td><strong>User Activity Analytics</strong></td><td>ðŸŸ¡ Medium</td><td>Requires <code>_audit</code> index access</td></tr>
<tr><td><strong>Alert Execution Analytics</strong></td><td>ðŸŸ¡ Medium</td><td>Requires <code>_internal</code> scheduler logs</td></tr>
<tr><td><strong>Search Pattern Analytics</strong></td><td>ðŸŸ¡ Medium</td><td>Requires <code>_audit</code> index access</td></tr>
<tr><td><strong>Volume & Capacity Analytics</strong></td><td>ðŸŸ  High</td><td>Requires <code>_internal</code> license_usage.log</td></tr>
<tr><td><strong>Ingestion Infrastructure</strong></td><td>ðŸŸ  High</td><td>Requires <code>_internal</code> metrics.log</td></tr>
<tr><td><strong>Ownership Mapping</strong></td><td>ðŸŸ¢ Low</td><td>Uses REST API (`</td><td>rest` command)</td></tr>
<tr><td><strong>Scheduler & Performance</strong></td><td>ðŸŸ¡ Medium</td><td>Requires <code>_internal</code> index access</td></tr>
</tbody>
</table>
<h3>Cloud Workarounds</h3>
<p>
If analytics files fail in Splunk Cloud:
</p>
<ol>
<li><strong>Check Permissions</strong>: Ensure your user/token has <code>admin<em>all</em>objects</code> and <code>search</code> capabilities</li>
<li><strong>Classic vs. Victoria</strong>: Victoria Experience may have different restrictions than Classic</li>
<li><strong>Support Ticket</strong>: Some organizations can request enhanced access to internal indexes</li>
<li><strong>Manual Export</strong>: For critical analytics, run the SPL query manually in Splunk Web and export results</li>
</ol>
<h3>File Status Indicators</h3>
<p>
When parsing export archives, DynaBridge handles missing analytics gracefully:
</p>
<pre><code class="language-json">{
  &quot;analytics_status&quot;: {
    &quot;dashboard_views_top100.json&quot;: &quot;success&quot;,
    &quot;daily_volume_by_index.json&quot;: &quot;failed_access_denied&quot;,
    &quot;users_most_active.json&quot;: &quot;success&quot;
  }
}</code></pre>
<hr>
<h2>File Categories Overview</h2>
<table>
<thead>
<tr><th>Category</th><th>Files</th><th>Primary Use Case</th><th>Enterprise</th><th>Cloud</th></tr>
</thead>
<tbody>
<tr><td><a href="#1-dashboard-analytics">Dashboard Analytics</a></td><td>4</td><td>Identify high-value dashboards to migrate</td><td>âœ… Full</td><td>ðŸŸ¡ Partial</td></tr>
<tr><td><a href="#2-user-activity-analytics">User Activity Analytics</a></td><td>4</td><td>Identify stakeholders and inactive users</td><td>âœ… Full</td><td>ðŸŸ¡ Partial</td></tr>
<tr><td><a href="#3-alert-analytics">Alert Analytics</a></td><td>6</td><td>Find critical alerts vs. elimination candidates</td><td>âœ… Full</td><td>ðŸŸ¡ Partial</td></tr>
<tr><td><a href="#4-search-pattern-analytics">Search Pattern Analytics</a></td><td>4</td><td>Understand query patterns for DQL conversion</td><td>âœ… Full</td><td>ðŸŸ¡ Partial</td></tr>
<tr><td><a href="#5-data-source-analytics">Data Source Analytics</a></td><td>4</td><td>Map data sources for ingestion planning</td><td>âœ… Full</td><td>ðŸŸ¡ Partial</td></tr>
<tr><td><a href="#6-volume--capacity-analytics">Volume & Capacity Analytics</a></td><td>8</td><td>Plan Dynatrace Grail bucket sizing</td><td>âœ… Full</td><td>ðŸŸ  Limited</td></tr>
<tr><td><a href="#7-ingestion-infrastructure-analytics">Ingestion Infrastructure</a></td><td>9</td><td>Understand data collection methods for OneAgent planning</td><td>âœ… Full</td><td>ðŸŸ  Limited</td></tr>
<tr><td><a href="#8-ownership-mapping-analytics">Ownership Mapping</a></td><td>3</td><td>Enable user-centric migration</td><td>âœ… Full</td><td>âœ… Full</td></tr>
<tr><td><a href="#9-scheduler--performance-analytics">Scheduler & Performance</a></td><td>4</td><td>Plan Dynatrace workflow capacity</td><td>âœ… Full</td><td>ðŸŸ¡ Partial</td></tr>
<tr><td><a href="#10-manifest--environment">Manifest & Environment</a></td><td>2</td><td>Export metadata and environment detection</td><td>âœ… Full</td><td>âœ… Full</td></tr>
</tbody>
</table>
<p>
<strong>Total: ~47 Script-Generated Files</strong>
</p>
<h3>Availability Legend</h3>
<table>
<thead>
<tr><th>Icon</th><th>Meaning</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td>âœ… Full</td><td>Available</td><td>All files in this category are expected to succeed</td></tr>
<tr><td>ðŸŸ¡ Partial</td><td>Likely Available</td><td>Most files succeed; some may fail depending on Cloud configuration</td></tr>
<tr><td>ðŸŸ  Limited</td><td>May Fail</td><td>Files require <code>_internal</code> index access which is often restricted in Cloud</td></tr>
</tbody>
</table>
<hr>
<h2>1. Dashboard Analytics</h2>
<h3>1.1 <code>dashboard<em>views</em>top100.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/dashboard<em>views</em>top100.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: ðŸŸ¡ Requires <code>_audit</code> index access - may fail in restricted Cloud environments
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted search_type=dashboard
| stats count as view_count, dc(user) as unique_users, latest(_time) as last_viewed
  by app, dashboard
| sort - view_count
| head 100</code></pre>
<p>
<strong>Description</strong>:
Lists the top 100 most-viewed dashboards in the Splunk environment over the analysis period (default 30 days). Includes view count, unique viewer count, and last access timestamp.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;results&quot;: [
    {
      &quot;app&quot;: &quot;security_app&quot;,
      &quot;dashboard&quot;: &quot;security_overview&quot;,
      &quot;view_count&quot;: 2345,
      &quot;unique_users&quot;: 45,
      &quot;last_viewed&quot;: &quot;2025-12-03T14:30:00Z&quot;
    }
  ]
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Prioritization</strong>: Dashboards with high view counts should be migrated first</li>
<li><strong>Stakeholder Identification</strong>: Unique user count helps identify which teams depend on each dashboard</li>
<li><strong>Validation</strong>: After migration, compare Dynatrace dashboard usage to baseline Splunk usage</li>
</ul>
<hr>
<h3>1.2 <code>dashboard<em>views</em>trend.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/dashboard<em>views</em>trend.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: ðŸŸ¡ Requires <code>_audit</code> index access - may fail in restricted Cloud environments
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted search_type=dashboard
| timechart span=1d count as views by dashboard limit=20</code></pre>
<p>
<strong>Description</strong>:
Daily view trends for the top 20 dashboards over the analysis period. Shows usage patterns over time.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Trend Analysis</strong>: Identify dashboards with growing vs. declining usage</li>
<li><strong>Timing</strong>: Schedule migration of high-trend dashboards during low-usage periods</li>
<li><strong>Seasonality</strong>: Detect dashboards with periodic usage (month-end reports, etc.)</li>
</ul>
<hr>
<h3>1.3 <code>dashboards<em>never</em>viewed.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/dashboards<em>never</em>viewed.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: ðŸŸ¡ Requires <code>_audit</code> index access - may fail in restricted Cloud environments
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted search_type=dashboard
| stats count by dashboard
| append [| rest /servicesNS/-/-/data/ui/views | table title | rename title as dashboard | eval count=0]
| stats sum(count) as total_views by dashboard
| where total_views=0</code></pre>
<p>
<strong>Description</strong>:
Lists all dashboards that have <strong>zero views</strong> during the analysis period. These are candidates for elimination rather than migration.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;results&quot;: [
    {&quot;dashboard&quot;: &quot;old_test_dashboard&quot;},
    {&quot;dashboard&quot;: &quot;legacy_report_v1&quot;},
    {&quot;dashboard&quot;: &quot;unused_prototype&quot;}
  ]
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Cost Reduction</strong>: Avoid migrating unused dashboards (saves conversion effort)</li>
<li><strong>Cleanup Opportunity</strong>: Present to stakeholders as archive/delete candidates</li>
<li><strong>Migration Scope</strong>: Reduce project scope by excluding dead weight</li>
</ul>
<hr>
<h3>1.4 <code>dashboard_ownership.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/dashboard_ownership.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: âœ… Uses REST API - works in both Enterprise and Cloud
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">| rest /servicesNS/-/-/data/ui/views
| table title, eai:acl.app, eai:acl.owner, eai:acl.sharing
| rename title as dashboard, eai:acl.app as app, eai:acl.owner as owner, eai:acl.sharing as sharing</code></pre>
<p>
<strong>Description</strong>:
Complete mapping of every dashboard to its owner, app, and sharing level.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;results&quot;: [
    {
      &quot;dashboard&quot;: &quot;security_overview&quot;,
      &quot;app&quot;: &quot;security_app&quot;,
      &quot;owner&quot;: &quot;jsmith&quot;,
      &quot;sharing&quot;: &quot;app&quot;
    }
  ]
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>User-Centric Migration</strong>: Show users only their own dashboards during migration</li>
<li><strong>Responsibility Assignment</strong>: Know who to contact for dashboard requirements</li>
<li><strong>Access Control</strong>: Map Splunk sharing to Dynatrace document permissions</li>
</ul>
<hr>
<h2>2. User Activity Analytics</h2>
<h3>2.1 <code>users<em>most</em>active.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/users<em>most</em>active.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: ðŸŸ¡ Requires <code>_audit</code> index access - may fail in restricted Cloud environments
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted
| stats count as search_count, dc(search) as unique_searches, latest(_time) as last_active
  by user
| sort - search_count
| head 50</code></pre>
<p>
<strong>Description</strong>:
Top 50 most active users ranked by search count. Shows total searches, variety of searches, and last activity time.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Stakeholder Engagement</strong>: Identify power users who should be consulted during migration</li>
<li><strong>Training Priority</strong>: Focus training on most active users first</li>
<li><strong>UAT Planning</strong>: Select active users for User Acceptance Testing</li>
</ul>
<hr>
<h3>2.2 <code>users_inactive.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/users_inactive.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted
| stats latest(_time) as last_active by user
| where last_active &lt; relative_time(now(), &quot;-30d&quot;)
| table user, last_active</code></pre>
<p>
<strong>Description</strong>:
Users with no search activity in the last 30 days.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Scope Reduction</strong>: Don't migrate personal content for inactive users</li>
<li><strong>License Planning</strong>: Identify users who may not need Dynatrace access</li>
<li><strong>Cleanup</strong>: Identify potential orphaned content</li>
</ul>
<hr>
<h3>2.3 <code>daily<em>active</em>users.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/daily<em>active</em>users.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted
| timechart span=1d dc(user) as active_users</code></pre>
<p>
<strong>Description</strong>:
Daily count of unique active users over the analysis period.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Adoption Baseline</strong>: Establish pre-migration user engagement metrics</li>
<li><strong>Post-Migration Comparison</strong>: Validate Dynatrace adoption matches Splunk usage</li>
<li><strong>Capacity Planning</strong>: Understand concurrent user patterns</li>
</ul>
<hr>
<h3>2.4 <code>activity<em>by</em>role.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/activity<em>by</em>role.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted
| stats count as searches, dc(user) as users by roles
| sort - searches</code></pre>
<p>
<strong>Description</strong>:
Search activity broken down by Splunk role.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Role-Based Migration</strong>: Prioritize migration for high-activity roles</li>
<li><strong>Permission Mapping</strong>: Map Splunk roles to Dynatrace IAM groups</li>
<li><strong>Training Planning</strong>: Customize training by role</li>
</ul>
<hr>
<h2>3. Alert Analytics</h2>
<h3>3.1 <code>alerts<em>most</em>fired.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/alerts<em>most</em>fired.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: ðŸŸ¡ Requires <code>_internal</code> index access - may fail in restricted Cloud environments
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=scheduler status=success savedsearch_name=*
| stats count as fire_count, avg(run_time) as avg_runtime, latest(_time) as last_fired
  by savedsearch_name, app
| where fire_count &gt; 0
| sort - fire_count
| head 100</code></pre>
<p>
<strong>Description</strong>:
Top 100 most frequently executed alerts with execution count, average runtime, and last execution time.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;results&quot;: [
    {
      &quot;savedsearch_name&quot;: &quot;Security - Failed Logins&quot;,
      &quot;app&quot;: &quot;security_app&quot;,
      &quot;fire_count&quot;: 2880,
      &quot;avg_runtime&quot;: 12.5,
      &quot;last_fired&quot;: &quot;2025-12-03T14:00:00Z&quot;
    }
  ]
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Critical Alert Identification</strong>: High-fire alerts are operationally critical</li>
<li><strong>Performance Planning</strong>: Runtime data helps plan Dynatrace workflow execution</li>
<li><strong>Conversion Priority</strong>: Migrate frequently-firing alerts first</li>
</ul>
<hr>
<h3>3.2 <code>alerts<em>with</em>actions.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/alerts<em>with</em>actions.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=scheduler status=success alert_actions!=&quot;&quot;
| stats count as action_count, values(alert_actions) as actions
  by savedsearch_name
| sort - action_count
| head 50</code></pre>
<p>
<strong>Description</strong>:
Alerts that have triggered actions (email, webhook, PagerDuty, etc.) ranked by action count.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Action Mapping</strong>: Identify Splunk alert actions to map to Dynatrace workflows</li>
<li><strong>Integration Discovery</strong>: Discover integrations (PagerDuty, Slack, etc.) to configure in Dynatrace</li>
<li><strong>Criticality Assessment</strong>: Alerts with actions are typically more critical</li>
</ul>
<hr>
<h3>3.3 <code>alerts_failed.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/alerts_failed.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=scheduler (status=failed OR status=skipped)
| stats count as failure_count, latest(status) as last_status, latest(reason) as last_reason
  by savedsearch_name
| sort - failure_count
| head 50</code></pre>
<p>
<strong>Description</strong>:
Alerts with execution failures or skips, including failure reasons.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Fix Before Migrate</strong>: Address broken alerts before converting to Dynatrace</li>
<li><strong>Elimination Candidates</strong>: Persistently failing alerts may be candidates for removal</li>
<li><strong>Root Cause Analysis</strong>: Understand why alerts fail to prevent issues in Dynatrace</li>
</ul>
<hr>
<h3>3.4 <code>alerts<em>never</em>fired.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/alerts<em>never</em>fired.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=scheduler
| stats count by savedsearch_name
| append [| rest /servicesNS/-/-/saved/searches search=&quot;alert.track=1&quot; | table title | rename title as savedsearch_name | eval count=0]
| stats sum(count) as total_fires by savedsearch_name
| where total_fires=0</code></pre>
<p>
<strong>Description</strong>:
Alerts that exist but have never executed during the analysis period.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Elimination Candidates</strong>: Why migrate alerts that never fire?</li>
<li><strong>Review Triggers</strong>: May indicate misconfigured schedules or conditions</li>
<li><strong>Scope Reduction</strong>: Reduce migration effort by excluding unused alerts</li>
</ul>
<hr>
<h3>3.5 <code>alert<em>firing</em>trend.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/alert<em>firing</em>trend.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=scheduler status=success
| timechart span=1d count as alert_fires by savedsearch_name limit=20</code></pre>
<p>
<strong>Description</strong>:
Daily firing trends for the top 20 alerts over the analysis period.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Trend Analysis</strong>: Identify alerts with increasing/decreasing activity</li>
<li><strong>Anomaly Detection</strong>: Spot unusual firing patterns before migration</li>
<li><strong>Baseline Establishment</strong>: Compare post-migration alert behavior</li>
</ul>
<hr>
<h3>3.6 <code>alert_ownership.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/alert_ownership.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">| rest /servicesNS/-/-/saved/searches
| table title, eai:acl.app, eai:acl.owner, eai:acl.sharing, is_scheduled, alert.track
| rename title as alert_name, eai:acl.app as app, eai:acl.owner as owner, eai:acl.sharing as sharing</code></pre>
<p>
<strong>Description</strong>:
Complete mapping of every saved search/alert to its owner, app, and scheduling status.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Ownership Tracking</strong>: Know who to contact for alert requirements</li>
<li><strong>User-Centric Migration</strong>: Show users their own alerts during conversion</li>
<li><strong>Responsibility Assignment</strong>: Assign migration tasks by owner</li>
</ul>
<hr>
<h2>4. Search Pattern Analytics</h2>
<h3>4.1 <code>search<em>commands</em>popular.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/search<em>commands</em>popular.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted search=*
| rex field=search &quot;^\s*\|?\s*(?&lt;first_command&gt;\w+)&quot;
| stats count by first_command
| sort - count
| head 30</code></pre>
<p>
<strong>Description</strong>:
Most frequently used SPL commands across all searches.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;results&quot;: [
    {&quot;first_command&quot;: &quot;search&quot;, &quot;count&quot;: 45678},
    {&quot;first_command&quot;: &quot;stats&quot;, &quot;count&quot;: 23456},
    {&quot;first_command&quot;: &quot;timechart&quot;, &quot;count&quot;: 12345}
  ]
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>DQL Mapping Priority</strong>: Focus SPLâ†’DQL conversion on most-used commands</li>
<li><strong>Training Focus</strong>: Train users on DQL equivalents of their most-used SPL</li>
<li><strong>Conversion Complexity</strong>: Identify commands that may require custom solutions</li>
</ul>
<hr>
<h3>4.2 <code>search<em>by</em>type.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/search<em>by</em>type.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted
| stats count by search_type
| sort - count</code></pre>
<p>
<strong>Description</strong>:
Search activity broken down by type (ad-hoc, scheduled, dashboard, etc.).
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Usage Pattern Understanding</strong>: Know the mix of interactive vs. scheduled queries</li>
<li><strong>Workflow Planning</strong>: High scheduled search count = more Dynatrace workflows needed</li>
<li><strong>User Behavior</strong>: Understand how users interact with data</li>
</ul>
<hr>
<h3>4.3 <code>searches_slow.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/searches_slow.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=completed
| where total_run_time &gt; 60
| stats count as slow_runs, avg(total_run_time) as avg_time, max(total_run_time) as max_time
  by search_id, user
| sort - avg_time
| head 50</code></pre>
<p>
<strong>Description</strong>:
Searches with runtime greater than 60 seconds, ranked by average runtime.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Performance Optimization</strong>: Identify queries that need optimization before/during migration</li>
<li><strong>DQL Optimization</strong>: Flag queries that may need different approaches in DQL</li>
<li><strong>Capacity Planning</strong>: Long-running queries impact Dynatrace query unit consumption</li>
</ul>
<hr>
<h3>4.4 <code>indexes_searched.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/indexes_searched.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted search=*
| rex field=search &quot;index=(?&lt;searched_index&gt;\w+)&quot;
| stats count by searched_index
| sort - count
| head 20</code></pre>
<p>
<strong>Description</strong>:
Most frequently searched indexes extracted from query patterns.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Data Ingestion Priority</strong>: Ensure frequently searched indexes are available in Grail</li>
<li><strong>Query Conversion</strong>: Know which indexes to map to Grail buckets in DQL</li>
<li><strong>Scope Definition</strong>: Focus data migration on actually-used indexes</li>
</ul>
<hr>
<h2>5. Data Source Analytics</h2>
<h3>5.1 <code>sourcetypes_searched.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/sourcetypes_searched.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted search=*
| rex field=search &quot;sourcetype=(?&lt;searched_sourcetype&gt;[\w:_-]+)&quot;
| stats count as search_count, dc(user) as users by searched_sourcetype
| sort - search_count
| head 50</code></pre>
<p>
<strong>Description</strong>:
Most frequently searched sourcetypes extracted from query patterns.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>OpenPipeline Priority</strong>: Create OpenPipeline processors for most-searched sourcetypes</li>
<li><strong>Field Extraction Planning</strong>: Focus DPL field extraction on high-value sourcetypes</li>
<li><strong>Data Mapping</strong>: Map Splunk sourcetypes to Dynatrace log attributes</li>
</ul>
<hr>
<h3>5.2 <code>indexes_queried.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/indexes_queried.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_audit action=search info=granted search=*
| rex field=search &quot;index=(?&lt;queried_index&gt;[\w_-]+)&quot;
| stats count as query_count, dc(user) as users by queried_index
| sort - query_count</code></pre>
<p>
<strong>Description</strong>:
All indexes that appear in search queries, ranked by query frequency.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Active Index Identification</strong>: Distinguish actively-queried indexes from dormant ones</li>
<li><strong>Bucket Mapping</strong>: Map queried indexes to Dynatrace Grail buckets</li>
<li><strong>Ingestion Planning</strong>: Prioritize data ingestion for actively-queried indexes</li>
</ul>
<hr>
<h3>5.3 <code>index_sizes.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/index_sizes.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">| dbinspect index=*
| stats sum(sizeOnDiskMB) as size_mb, sum(eventCount) as events by index
| sort - size_mb</code></pre>
<p>
<strong>Description</strong>:
Storage size and event count for each index.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Grail Capacity Planning</strong>: Size Dynatrace buckets based on Splunk index sizes</li>
<li><strong>Cost Estimation</strong>: Estimate Dynatrace storage costs based on volume</li>
<li><strong>Retention Planning</strong>: Compare Splunk retention to Grail retention requirements</li>
</ul>
<hr>
<h3>5.4 <code>saved<em>searches</em>all.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/saved<em>searches</em>all.json</code>
</p>
<p>
<strong>REST API Source</strong>: <code>GET /services/saved/searches</code>
</p>
<p>
<strong>Description</strong>:
Complete metadata for all saved searches from Splunk REST API.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Comprehensive Inventory</strong>: Full saved search catalog for migration planning</li>
<li><strong>Query Extraction</strong>: Extract SPL queries for conversion to DQL</li>
<li><strong>Schedule Analysis</strong>: Understand scheduling patterns for Dynatrace workflow setup</li>
</ul>
<hr>
<h2>6. Volume & Capacity Analytics</h2>
<h3>6.1 <code>daily<em>volume</em>by_index.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/daily<em>volume</em>by_index.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: ðŸŸ  Requires <code><em>internal</code> license</em>usage.log - often restricted in Cloud environments
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-30d@d
| timechart span=1d sum(b) as bytes by idx
| eval gb=round(bytes/1024/1024/1024,2)
| fields _time, idx, gb</code></pre>
<p>
<strong>Description</strong>:
Daily ingestion volume (GB) per index over the last 30 days.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Grail Bucket Sizing</strong>: Size each bucket based on actual daily volume</li>
<li><strong>Trend Analysis</strong>: Identify growing indexes that need capacity headroom</li>
<li><strong>Cost Projection</strong>: Project Dynatrace ingestion costs by index</li>
</ul>
<hr>
<h3>6.2 <code>daily<em>volume</em>by_sourcetype.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/daily<em>volume</em>by_sourcetype.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-30d@d
| timechart span=1d sum(b) as bytes by st
| eval gb=round(bytes/1024/1024/1024,2)
| fields _time, st, gb</code></pre>
<p>
<strong>Description</strong>:
Daily ingestion volume (GB) per sourcetype over the last 30 days.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>OpenPipeline Sizing</strong>: Size processing capacity by sourcetype volume</li>
<li><strong>Log Source Mapping</strong>: Map Splunk sourcetypes to Dynatrace log sources</li>
<li><strong>Optimization Targets</strong>: Identify high-volume sourcetypes for compression/filtering</li>
</ul>
<hr>
<h3>6.3 <code>daily<em>volume</em>summary.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/daily<em>volume</em>summary.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-30d@d
| timechart span=1d sum(b) as bytes
| eval gb=round(bytes/1024/1024/1024,2)
| stats avg(gb) as avg_daily_gb, max(gb) as peak_daily_gb, sum(gb) as total_30d_gb</code></pre>
<p>
<strong>Description</strong>:
Summary statistics: average daily volume, peak daily volume, and 30-day total.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;results&quot;: [
    {
      &quot;avg_daily_gb&quot;: 125.5,
      &quot;peak_daily_gb&quot;: 189.2,
      &quot;total_30d_gb&quot;: 3765.0
    }
  ]
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>License Planning</strong>: Estimate Dynatrace DPS/DDU requirements</li>
<li><strong>Peak Capacity</strong>: Plan for peak ingestion days</li>
<li><strong>Budget Estimation</strong>: Project monthly/annual Dynatrace costs</li>
</ul>
<hr>
<h3>6.4 <code>daily<em>events</em>by_index.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/daily<em>events</em>by_index.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*metrics.log group=per_index_thruput earliest=-30d@d
| timechart span=1d sum(ev) as events by series
| rename series as index</code></pre>
<p>
<strong>Description</strong>:
Daily event count per index over the last 30 days.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Event Rate Planning</strong>: Understand events per second (EPS) by index</li>
<li><strong>Query Performance</strong>: High event counts may impact DQL query performance</li>
<li><strong>Sampling Strategy</strong>: Identify indexes that may benefit from sampling</li>
</ul>
<hr>
<h3>6.5 <code>hourly<em>volume</em>pattern.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/hourly<em>volume</em>pattern.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-7d
| eval hour=strftime(_time, &quot;%H&quot;)
| stats sum(b) as bytes by hour
| eval gb=round(bytes/1024/1024/1024,2)
| sort hour</code></pre>
<p>
<strong>Description</strong>:
Hourly ingestion pattern showing which hours have highest volume.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Peak Hour Identification</strong>: Know when peak ingestion occurs</li>
<li><strong>Maintenance Windows</strong>: Schedule migrations during low-volume hours</li>
<li><strong>Burst Capacity</strong>: Plan Dynatrace capacity for peak hours</li>
</ul>
<hr>
<h3>6.6 <code>top<em>indexes</em>by_volume.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/top<em>indexes</em>by_volume.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-30d@d
| stats sum(b) as total_bytes by idx
| eval daily_avg_gb=round((total_bytes/30)/1024/1024/1024,2)
| sort - daily_avg_gb
| head 20</code></pre>
<p>
<strong>Description</strong>:
Top 20 indexes ranked by daily average volume.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>80/20 Analysis</strong>: Typically 20% of indexes contain 80% of volume</li>
<li><strong>Migration Priority</strong>: Focus on high-volume indexes for biggest impact</li>
<li><strong>Cost Optimization</strong>: Identify indexes for potential filtering/sampling</li>
</ul>
<hr>
<h3>6.7 <code>top<em>sourcetypes</em>by_volume.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/top<em>sourcetypes</em>by_volume.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-30d@d
| stats sum(b) as total_bytes by st
| eval daily_avg_gb=round((total_bytes/30)/1024/1024/1024,2)
| sort - daily_avg_gb
| head 20</code></pre>
<p>
<strong>Description</strong>:
Top 20 sourcetypes ranked by daily average volume.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>OpenPipeline Priority</strong>: Build processors for highest-volume sourcetypes first</li>
<li><strong>Parsing Optimization</strong>: Focus parsing effort on high-volume data</li>
<li><strong>Field Extraction ROI</strong>: Extract fields from sourcetypes with most data</li>
</ul>
<hr>
<h3>6.8 <code>top<em>hosts</em>by_volume.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/top<em>hosts</em>by_volume.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-30d@d
| stats sum(b) as total_bytes by h
| eval daily_avg_gb=round((total_bytes/30)/1024/1024/1024,2)
| sort - daily_avg_gb
| head 50</code></pre>
<p>
<strong>Description</strong>:
Top 50 hosts ranked by daily average volume sent.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>OneAgent Deployment</strong>: Prioritize OneAgent installation on high-volume hosts</li>
<li><strong>Infrastructure Mapping</strong>: Map Splunk forwarder hosts to Dynatrace monitored hosts</li>
<li><strong>Troubleshooting</strong>: Identify chatty hosts that may need log filtering</li>
</ul>
<hr>
<h2>7. Ingestion Infrastructure Analytics</h2>
<h3>7.1 <code>by<em>connection</em>type.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/by</em>connection_type.json</code>
</p>
<p>
<strong>Cloud Availability</strong>: ðŸŸ  Requires <code>_internal</code> metrics.log - often restricted in Cloud environments
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=splunkd source=*metrics.log group=tcpin_connections earliest=-7d
| stats dc(sourceHost) as unique_hosts, sum(kb) as total_kb by connectionType
| eval total_gb=round(total_kb/1024/1024,2), daily_avg_gb=round(total_gb/7,2)</code></pre>
<p>
<strong>Description</strong>:
Data ingestion broken down by connection type (cooked from UF, raw from HF, etc.).
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Forwarder Inventory</strong>: Understand ratio of Universal vs. Heavy Forwarders</li>
<li><strong>OneAgent Planning</strong>: Plan log ingestion method based on forwarder architecture</li>
<li><strong>Migration Strategy</strong>: Determine if logs can route directly to Dynatrace</li>
</ul>
<hr>
<h3>7.2 <code>by<em>input</em>method.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/by</em>input_method.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=splunkd source=*metrics.log group=per_source_thruput earliest=-7d
| rex field=series &quot;^(?&lt;input_type&gt;[^:]+):&quot;
| stats sum(kb) as total_kb, dc(series) as unique_sources by input_type
| eval total_gb=round(total_kb/1024/1024,2), daily_avg_gb=round(total_gb/7,2)
| sort - total_kb</code></pre>
<p>
<strong>Description</strong>:
Data ingestion broken down by input method (splunktcp, http, monitor, udp, tcp, etc.).
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Input Mapping</strong>: Map Splunk inputs to Dynatrace ingestion methods</li>
<li><strong>HEC Migration</strong>: Identify HEC usage for migration to Dynatrace Log Ingest API</li>
<li><strong>Syslog Planning</strong>: Plan Dynatrace ActiveGate syslog receivers</li>
</ul>
<hr>
<h3>7.3 <code>hec_usage.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/hec</em>usage.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=splunkd source=*metrics.log group=per_source_thruput series=http:* earliest=-7d
| stats sum(kb) as total_kb, dc(series) as token_count
| eval total_gb=round(total_kb/1024/1024,2), daily_avg_gb=round(total_gb/7,2)</code></pre>
<p>
<strong>Description</strong>:
HTTP Event Collector (HEC) usage statistics including volume and token count.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>API Migration</strong>: Size Dynatrace Log Ingest API capacity</li>
<li><strong>Token Mapping</strong>: Plan API token migration from Splunk HEC to Dynatrace</li>
<li><strong>Application Integration</strong>: Identify applications sending data via HEC</li>
</ul>
<hr>
<h3>7.4 <code>forwarding_hosts.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/forwarding</em>hosts.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=splunkd source=*metrics.log group=tcpin_connections earliest=-7d
| stats sum(kb) as total_kb, latest(_time) as last_seen, values(connectionType) as connection_types
  by sourceHost
| eval total_gb=round(total_kb/1024/1024,2)
| sort - total_kb
| head 500</code></pre>
<p>
<strong>Description</strong>:
Inventory of up to 500 forwarding hosts with volume, last activity, and connection type.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>OneAgent Deployment List</strong>: Direct list of hosts needing OneAgent installation</li>
<li><strong>Forwarder Migration</strong>: Plan OneAgent Splunk Forwarder extension deployment</li>
<li><strong>Infrastructure Mapping</strong>: Map Splunk forwarder topology to Dynatrace hosts</li>
</ul>
<hr>
<h3>7.5 <code>by<em>sourcetype</em>category.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/by</em>sourcetype_category.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal source=*license_usage.log type=Usage earliest=-30d
| stats sum(b) as bytes, dc(h) as unique_hosts by st
| eval daily_avg_gb=round((bytes/30)/1024/1024/1024,2)
| eval category=case(
    match(st,&quot;^otel|^otlp|opentelemetry&quot;),&quot;opentelemetry&quot;,
    match(st,&quot;^aws:|^azure:|^gcp:|^cloud&quot;),&quot;cloud&quot;,
    match(st,&quot;^WinEventLog|^windows|^wmi&quot;),&quot;windows&quot;,
    match(st,&quot;^linux|^syslog|^nix&quot;),&quot;linux_unix&quot;,
    match(st,&quot;^cisco:|^pan:|^juniper:|^fortinet:|^f5:|^checkpoint&quot;),&quot;network_security&quot;,
    match(st,&quot;^access_combined|^nginx|^apache|^iis&quot;),&quot;web&quot;,
    match(st,&quot;^docker|^kube|^container&quot;),&quot;containers&quot;,
    1=1,&quot;other&quot;
  )
| stats sum(daily_avg_gb) as daily_avg_gb, sum(unique_hosts) as unique_hosts, values(st) as sourcetypes
  by category
| sort - daily_avg_gb</code></pre>
<p>
<strong>Description</strong>:
Sourcetypes grouped into logical categories (OpenTelemetry, cloud, Windows, Linux, network/security, web, containers, other).
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Migration Strategy</strong>: Different categories may have different migration paths</li>
<li><strong>OpenTelemetry Detection</strong>: Identify if OTel data is already in Splunk</li>
<li><strong>Dynatrace Entity Mapping</strong>: Map log categories to Dynatrace entity types</li>
</ul>
<hr>
<h3>7.6 <code>data<em>inputs</em>by_app.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/data</em>inputs<em>by</em>app.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">| rest /servicesNS/-/-/data/inputs/all
| stats count by eai:acl.app, disabled
| eval status=if(disabled=&quot;0&quot;,&quot;enabled&quot;,&quot;disabled&quot;)
| stats count by eai:acl.app, status</code></pre>
<p>
<strong>Description</strong>:
Data input definitions grouped by app with enabled/disabled status.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Input Inventory</strong>: Complete catalog of data inputs per app</li>
<li><strong>Active vs. Disabled</strong>: Focus on enabled inputs only</li>
<li><strong>App Dependencies</strong>: Understand which apps have data input dependencies</li>
</ul>
<hr>
<h3>7.7 <code>syslog_inputs.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/syslog</em>inputs.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=splunkd source=*metrics.log group=per_source_thruput earliest=-7d
| search series=udp:* OR series=tcp:*
| stats sum(kb) as total_kb by series
| eval total_gb=round(total_kb/1024/1024,2)
| sort - total_kb</code></pre>
<p>
<strong>Description</strong>:
Syslog input volume breakdown by UDP and TCP listeners.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Syslog Migration</strong>: Plan Dynatrace ActiveGate syslog receiver configuration</li>
<li><strong>Port Mapping</strong>: Identify ports used for syslog collection</li>
<li><strong>Volume Planning</strong>: Size syslog ingestion capacity in Dynatrace</li>
</ul>
<hr>
<h3>7.8 <code>scripted_inputs.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion<em>infrastructure/scripted</em>inputs.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">| rest /servicesNS/-/-/data/inputs/script
| stats count by eai:acl.app, disabled, interval
| eval status=if(disabled=&quot;0&quot;,&quot;enabled&quot;,&quot;disabled&quot;)</code></pre>
<p>
<strong>Description</strong>:
Inventory of scripted inputs with app, status, and execution interval.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Custom Integration Mapping</strong>: Scripted inputs often represent custom integrations</li>
<li><strong>Extension Planning</strong>: May need Dynatrace extensions to replace scripted inputs</li>
<li><strong>OneAgent Extension</strong>: Some scripts may be replaceable by OneAgent capabilities</li>
</ul>
<hr>
<h3>7.9 <code>summary.json</code> (Ingestion)</h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ingestion_infrastructure/summary.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=splunkd source=*metrics.log group=tcpin_connections earliest=-7d
| stats dc(sourceHost) as total_forwarding_hosts, sum(kb) as total_kb
| eval total_gb=round(total_kb/1024/1024,2), daily_avg_gb=round(total_gb/7,2)</code></pre>
<p>
<strong>Description</strong>:
High-level summary of forwarding infrastructure: total hosts, total volume, daily average.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Migration Scope</strong>: Quick view of infrastructure size</li>
<li><strong>OneAgent Deployment Scale</strong>: Number of hosts requiring agent installation</li>
<li><strong>Capacity Planning</strong>: Total daily ingestion volume for Dynatrace sizing</li>
</ul>
<hr>
<h2>8. Ownership Mapping Analytics</h2>
<h3>8.1 <code>dashboard_ownership.json</code></h3>
<p>
<em>See <a href="#14-dashboard_ownershipjson">Section 1.4</a> above</em>
</p>
<hr>
<h3>8.2 <code>alert_ownership.json</code></h3>
<p>
<em>See <a href="#36-alert_ownershipjson">Section 3.6</a> above</em>
</p>
<hr>
<h3>8.3 <code>ownership_summary.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/ownership_summary.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">| rest /servicesNS/-/-/data/ui/views
| stats count as dashboards by eai:acl.owner
| rename eai:acl.owner as owner
| append [| rest /servicesNS/-/-/saved/searches | stats count as alerts by eai:acl.owner | rename eai:acl.owner as owner]
| stats sum(dashboards) as dashboards, sum(alerts) as alerts by owner
| sort - dashboards</code></pre>
<p>
<strong>Description</strong>:
Summary of dashboard and alert ownership by user.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;results&quot;: [
    {&quot;owner&quot;: &quot;jsmith&quot;, &quot;dashboards&quot;: 45, &quot;alerts&quot;: 23},
    {&quot;owner&quot;: &quot;security_team&quot;, &quot;dashboards&quot;: 32, &quot;alerts&quot;: 67},
    {&quot;owner&quot;: &quot;admin&quot;, &quot;dashboards&quot;: 28, &quot;alerts&quot;: 45}
  ]
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Workload Distribution</strong>: Identify owners with most content to migrate</li>
<li><strong>Task Assignment</strong>: Assign migration tasks based on ownership</li>
<li><strong>Stakeholder Identification</strong>: Large owners are key stakeholders</li>
</ul>
<hr>
<h2>9. Scheduler & Performance Analytics</h2>
<h3>9.1 <code>scheduler_load.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/scheduler_load.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">index=_internal sourcetype=scheduler
| timechart span=1h count as scheduled_searches, avg(run_time) as avg_runtime</code></pre>
<p>
<strong>Description</strong>:
Hourly scheduler activity showing search count and average runtime.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Workflow Capacity</strong>: Plan Dynatrace workflow execution capacity</li>
<li><strong>Peak Hours</strong>: Identify scheduler load patterns for workflow scheduling</li>
<li><strong>Performance Baseline</strong>: Establish pre-migration scheduler performance</li>
</ul>
<hr>
<h3>9.2 <code>saved<em>searches</em>by_owner.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/saved<em>searches</em>by_owner.json</code>
</p>
<p>
<strong>SPL Query Source</strong>:
</p>
<pre><code class="language-spl">| rest /servicesNS/-/-/saved/searches
| stats count by eai:acl.owner
| sort - count
| head 30</code></pre>
<p>
<strong>Description</strong>:
Top 30 saved search owners ranked by search count.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Owner Identification</strong>: Know who owns the most scheduled content</li>
<li><strong>Migration Assignment</strong>: Distribute conversion work by ownership</li>
<li><strong>Stakeholder Priority</strong>: High-count owners are key stakeholders</li>
</ul>
<hr>
<h3>9.3 <code>recent_searches.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/recent_searches.json</code>
</p>
<p>
<strong>REST API Source</strong>: <code>GET /services/search/jobs?count=1000</code>
</p>
<p>
<strong>Description</strong>:
Last 1000 search jobs with full metadata from Splunk REST API.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Search Pattern Analysis</strong>: Understand recent query patterns</li>
<li><strong>Performance Metrics</strong>: Runtime and result count for recent searches</li>
<li><strong>User Behavior</strong>: Who's running what queries</li>
</ul>
<hr>
<h3>9.4 <code>kvstore_stats.json</code></h3>
<p>
<strong>Location</strong>: <code><em>usage</em>analytics/kvstore_stats.json</code>
</p>
<p>
<strong>REST API Source</strong>: <code>GET /services/server/introspection/kvstore</code>
</p>
<p>
<strong>Description</strong>:
KV Store statistics and health metrics.
</p>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>KV Store Migration</strong>: Identify KV Store collections for potential migration</li>
<li><strong>Data Dependencies</strong>: Dashboard Studio uses KV Store - understand dependencies</li>
<li><strong>Capacity Planning</strong>: KV Store size impacts Dashboard Studio migration</li>
</ul>
<hr>
<h2>10. Manifest & Environment</h2>
<h3>10.1 <code>manifest.json</code></h3>
<p>
<strong>Location</strong>: Root of export (<code>manifest.json</code>)
</p>
<p>
<strong>Generated By</strong>: Export script aggregation logic
</p>
<p>
<strong>Description</strong>:
Master manifest containing all export metadata, statistics, and migration intelligence summaries.
</p>
<p>
<strong>Key Contents</strong>:
</p>
<ul>
<li>Schema version and tool version</li>
<li>Source environment details (hostname, Splunk version, architecture)</li>
<li>Collection options used</li>
<li>Statistics (apps, dashboards, alerts, users, indexes)</li>
<li>Usage intelligence summary (top dashboards, top alerts, elimination candidates)</li>
<li>Volume summaries</li>
<li>Checksums</li>
</ul>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Programmatic Parsing</strong>: DynaBridge parser reads manifest first</li>
<li><strong>Migration Planning</strong>: High-level statistics for project scoping</li>
<li><strong>Validation</strong>: Checksums ensure export integrity</li>
</ul>
<hr>
<h3>10.2 <code>environment.json</code></h3>
<p>
<strong>Location</strong>: <code>_systeminfo/environment.json</code>
</p>
<p>
<strong>Generated By</strong>: Script environment detection logic
</p>
<p>
<strong>Description</strong>:
Detected environment profile including hostname, platform, Splunk version, and deployment architecture.
</p>
<p>
<strong>Sample Output</strong>:
</p>
<pre><code class="language-json">{
  &quot;hostname&quot;: &quot;splunk-sh01&quot;,
  &quot;fqdn&quot;: &quot;splunk-sh01.company.com&quot;,
  &quot;platform&quot;: &quot;Linux&quot;,
  &quot;platform_version&quot;: &quot;5.4.0-150-generic&quot;,
  &quot;architecture&quot;: &quot;x86_64&quot;,
  &quot;splunk_home&quot;: &quot;/opt/splunk&quot;,
  &quot;splunk_flavor&quot;: &quot;enterprise&quot;,
  &quot;splunk_role&quot;: &quot;search_head&quot;,
  &quot;splunk_architecture&quot;: &quot;distributed&quot;,
  &quot;splunk_version&quot;: &quot;9.1.3&quot;,
  &quot;export_timestamp&quot;: &quot;2025-12-03T14:25:30Z&quot;,
  &quot;export_version&quot;: &quot;4.0.0&quot;
}</code></pre>
<p>
<strong>DynaBridge Migration Purpose</strong>:
</p>
<ul>
<li><strong>Environment Identification</strong>: Distinguish exports from different environments</li>
<li><strong>Architecture Understanding</strong>: Distributed vs. standalone impacts migration approach</li>
<li><strong>Version Compatibility</strong>: Ensure SPL/DQL conversion considers Splunk version</li>
</ul>
<hr>
<h2>Quick Reference: Files by Migration Use Case</h2>
<h3>Use Case 1: Dashboard Migration Prioritization</h3>
<table>
<thead>
<tr><th>File</th><th>Use</th></tr>
</thead>
<tbody>
<tr><td><code>dashboard_views_top100.json</code></td><td>Which dashboards to migrate first</td></tr>
<tr><td><code>dashboards_never_viewed.json</code></td><td>Which dashboards to skip</td></tr>
<tr><td><code>dashboard_ownership.json</code></td><td>Who to contact for each dashboard</td></tr>
</tbody>
</table>
<h3>Use Case 2: Alert Migration Prioritization</h3>
<table>
<thead>
<tr><th>File</th><th>Use</th></tr>
</thead>
<tbody>
<tr><td><code>alerts_most_fired.json</code></td><td>Which alerts to migrate first</td></tr>
<tr><td><code>alerts_with_actions.json</code></td><td>Which alerts have integrations to map</td></tr>
<tr><td><code>alerts_never_fired.json</code></td><td>Which alerts to skip</td></tr>
<tr><td><code>alerts_failed.json</code></td><td>Which alerts to fix or eliminate</td></tr>
<tr><td><code>alert_ownership.json</code></td><td>Who to contact for each alert</td></tr>
</tbody>
</table>
<h3>Use Case 3: Data Ingestion Planning</h3>
<table>
<thead>
<tr><th>File</th><th>Use</th></tr>
</thead>
<tbody>
<tr><td><code>daily_volume_summary.json</code></td><td>Total ingestion volume for licensing</td></tr>
<tr><td><code>top_indexes_by_volume.json</code></td><td>Which indexes to prioritize</td></tr>
<tr><td><code>top_sourcetypes_by_volume.json</code></td><td>Which sourcetypes need OpenPipeline</td></tr>
<tr><td><code>forwarding_hosts.json</code></td><td>Hosts needing OneAgent deployment</td></tr>
<tr><td><code>by_connection_type.json</code></td><td>Forwarder type distribution</td></tr>
</tbody>
</table>
<h3>Use Case 4: Capacity Planning</h3>
<table>
<thead>
<tr><th>File</th><th>Use</th></tr>
</thead>
<tbody>
<tr><td><code>daily_volume_summary.json</code></td><td>Average and peak daily GB</td></tr>
<tr><td><code>hourly_volume_pattern.json</code></td><td>Peak hour identification</td></tr>
<tr><td><code>index_sizes.json</code></td><td>Total storage requirements</td></tr>
<tr><td><code>scheduler_load.json</code></td><td>Workflow execution capacity</td></tr>
</tbody>
</table>
<h3>Use Case 5: Stakeholder Identification</h3>
<table>
<thead>
<tr><th>File</th><th>Use</th></tr>
</thead>
<tbody>
<tr><td><code>users_most_active.json</code></td><td>Power users to engage</td></tr>
<tr><td><code>users_inactive.json</code></td><td>Users to deprioritize</td></tr>
<tr><td><code>ownership_summary.json</code></td><td>Content owners by volume</td></tr>
</tbody>
</table>
<h3>Use Case 6: Cleanup Before Migration</h3>
<table>
<thead>
<tr><th>File</th><th>Use</th></tr>
</thead>
<tbody>
<tr><td><code>dashboards_never_viewed.json</code></td><td>Dashboards to archive/delete</td></tr>
<tr><td><code>alerts_never_fired.json</code></td><td>Alerts to review/delete</td></tr>
<tr><td><code>alerts_failed.json</code></td><td>Broken alerts to fix/delete</td></tr>
<tr><td><code>users_inactive.json</code></td><td>Personal content to skip</td></tr>
</tbody>
</table>
<hr>
<h2>Appendix A: Complete Cloud Availability Reference</h2>
<p>
This table provides Cloud availability status for <strong>all 47 script-generated analytics files</strong>.
</p>
<h3>Dashboard Analytics (4 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>dashboard_views_top100.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>dashboard_views_trend.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>dashboards_never_viewed.json</code></td><td><code>index=_audit</code> + REST</td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>dashboard_ownership.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
</tbody>
</table>
<h3>User Activity Analytics (4 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>users_most_active.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>users_inactive.json</code></td><td><code>index=_audit</code> + REST</td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>daily_active_users.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>activity_by_role.json</code></td><td><code>index=_audit</code> + REST</td><td>ðŸŸ¡ May fail</td></tr>
</tbody>
</table>
<h3>Alert Analytics (6 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>alerts_most_fired.json</code></td><td><code>index=_internal</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>alerts_with_actions.json</code></td><td><code>index=_internal</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>alerts_failed.json</code></td><td><code>index=_internal</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>alerts_never_fired.json</code></td><td><code>index=_internal</code> + REST</td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>alert_firing_trend.json</code></td><td><code>index=_internal</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>alert_ownership.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
</tbody>
</table>
<h3>Search Pattern Analytics (4 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>search_commands_popular.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>search_by_type.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>searches_slow.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>indexes_searched.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
</tbody>
</table>
<h3>Data Source Analytics (4 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>sourcetypes_searched.json</code></td><td><code>index=_audit</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>indexes_queried.json</code></td><td><code>index=_internal</code></td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>index_sizes.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
<tr><td><code>saved_searches_all.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
</tbody>
</table>
<h3>Volume & Capacity Analytics (8 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>daily_volume_by_index.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>daily_volume_by_sourcetype.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>daily_volume_summary.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>daily_events_by_index.json</code></td><td><code>index=_internal</code> metrics</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>hourly_volume_pattern.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>top_indexes_by_volume.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>top_sourcetypes_by_volume.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>top_hosts_by_volume.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
</tbody>
</table>
<h3>Ingestion Infrastructure Analytics (9 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>by_connection_type.json</code></td><td><code>index=_internal</code> metrics</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>by_input_method.json</code></td><td><code>index=_internal</code> metrics</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>hec_usage.json</code></td><td><code>index=_internal</code> metrics</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>forwarding_hosts.json</code></td><td><code>index=_internal</code> metrics</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>by_sourcetype_category.json</code></td><td><code>index=_internal</code> license_usage</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>data_inputs_by_app.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
<tr><td><code>syslog_inputs.json</code></td><td><code>index=_internal</code> metrics</td><td>ðŸŸ  Often fails</td></tr>
<tr><td><code>scripted_inputs.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
<tr><td><code>summary.json</code></td><td><code>index=_internal</code> metrics</td><td>ðŸŸ  Often fails</td></tr>
</tbody>
</table>
<h3>Ownership Mapping Analytics (3 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>dashboard_ownership.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
<tr><td><code>alert_ownership.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
<tr><td><code>ownership_summary.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
</tbody>
</table>
<h3>Scheduler & Performance Analytics (4 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>scheduler_load.json</code></td><td><code>index=_internal</code></td><td>ðŸŸ¡ May fail</td></tr>
<tr><td><code>saved_searches_by_owner.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
<tr><td><code>recent_searches.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
<tr><td><code>kvstore_stats.json</code></td><td>REST API</td><td>âœ… Works</td></tr>
</tbody>
</table>
<h3>Manifest & Environment (2 files)</h3>
<table>
<thead>
<tr><th>File</th><th>Data Source</th><th>Cloud Status</th></tr>
</thead>
<tbody>
<tr><td><code>manifest.json</code></td><td>Script-generated</td><td>âœ… Works</td></tr>
<tr><td><code>environment.json</code></td><td>Script-generated</td><td>âœ… Works</td></tr>
</tbody>
</table>
<h3>Summary by Cloud Status</h3>
<table>
<thead>
<tr><th>Status</th><th>Count</th><th>Percentage</th></tr>
</thead>
<tbody>
<tr><td>âœ… Works (REST API / Script-generated)</td><td>16</td><td>34%</td></tr>
<tr><td>ðŸŸ¡ May fail (<code>_audit</code> dependent)</td><td>14</td><td>30%</td></tr>
<tr><td>ðŸŸ  Often fails (<code>_internal</code> dependent)</td><td>17</td><td>36%</td></tr>
</tbody>
</table>
<h3>Cloud Migration Recommendations</h3>
<ol>
<li><strong>Start with guaranteed files</strong>: Focus on REST API-based files first (ownership, saved searches, index sizes)</li>
<li><strong>Test internal access</strong>: Run a test query against <code><em>audit</code> and <code></em>internal</code> to determine your Cloud tier's access level</li>
<li><strong>Request access</strong>: If volume/ingestion analytics are critical, file a support ticket to request <code>_internal</code> access</li>
<li><strong>Alternative volume data</strong>: Use Splunk Cloud's License Usage Report dashboard as an alternative to volume analytics</li>
<li><strong>Document gaps</strong>: If analytics fail, document this for manual migration planning</li>
</ol>
<hr>
<h2>Appendix B: SPL to DQL Considerations</h2>
<p>
When converting queries that reference these analytics, remember:
</p>
<table>
<thead>
<tr><th>Splunk Concept</th><th>Dynatrace Equivalent</th></tr>
</thead>
<tbody>
<tr><td><code>index=_audit</code></td><td>No direct equivalent - use Dynatrace audit logs</td></tr>
<tr><td><code>index=_internal</code></td><td>No direct equivalent - use Dynatrace platform metrics</td></tr>
<tr><td>`</td><td>stats`</td><td>`</td><td>summarize` in DQL</td></tr>
<tr><td>`</td><td>timechart`</td><td>`</td><td>makeTimeseries` in DQL</td></tr>
<tr><td>`</td><td>rex`</td><td>`</td><td>parse` with DPL in DQL</td></tr>
<tr><td><code>sourcetype</code></td><td>Log attribute or <code>log.source</code></td></tr>
<tr><td><code>index</code></td><td>Grail bucket or <code>dt.system.bucket</code></td></tr>
</tbody>
</table>
<hr>
<p>
<em>Document Version: 4.0.0</em>
<em>Applies To: DynaBridge Splunk Enterprise & Cloud Export Scripts</em>
<em>Last Updated: January 2026</em>
</p>
    </main>

    <footer class="footer">
        <div class="footer-content">
            <div class="footer-logo"><span class="highlight">Dyna</span>Bridge for Splunk</div>
            <p>Migration intelligence for Splunk to Dynatrace Gen3 Grail</p>
            <div class="footer-links">
                <a href="README-SPLUNK-ENTERPRISE.html">Enterprise Guide</a>
                <a href="README-SPLUNK-CLOUD.html">Cloud Guide</a>
                <a href="SCRIPT-GENERATED-ANALYTICS-REFERENCE.html">Analytics</a>
                <a href="EXPORT-SCHEMA.html">Schema</a>
            </div>
            <p class="footer-copyright">DynaBridge Project &bull; Built for Dynatrace Gen3 Platform</p>
        </div>
    </footer>
</body>
</html>
